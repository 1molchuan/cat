
import streamlit as st
import time
import random
from datetime import datetime, timedelta
import json
import base64
import io
from io import BytesIO
import re
import requests
import urllib3
import contextlib
import threading
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError:
    PDFPLUMBER_AVAILABLE = False

# æ£€æŸ¥ python-docx åº“æ˜¯å¦å¯ç”¨
try:
    import docx
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    docx = None

# è”ç½‘æœç´¢åŠŸèƒ½å·²æ”¹ç”¨ Tavily APIï¼Œæ— éœ€é¢å¤–å¯¼å…¥
SEARCH_AVAILABLE = True

# å¯¼å…¥ OpenAIï¼Œå¤„ç†å¯èƒ½çš„ç±»å‹æ³¨è§£é”™è¯¯
# æ³¨æ„ï¼šå¦‚æœé‡åˆ° "Parameters to Generic[...] must all be type variables" é”™è¯¯
# è¿™é€šå¸¸æ˜¯ openai åº“çš„ç±»å‹æ³¨è§£é—®é¢˜ï¼Œä¸å½±å“å®é™…è¿è¡Œ
# è§£å†³æ–¹æ³•ï¼šæ›´æ–° openai åº“æˆ–ä½¿ç”¨ type: ignore å¿½ç•¥
import sys
import warnings

# å¿½ç•¥ç±»å‹ç›¸å…³çš„è­¦å‘Šå’Œé”™è¯¯
warnings.filterwarnings('ignore', category=DeprecationWarning)

try:
    # å°è¯•æ­£å¸¸å¯¼å…¥
    from openai import OpenAI
except TypeError as e:
    if "Generic" in str(e) or "type variables" in str(e):
        # è¿™æ˜¯ç±»å‹æ³¨è§£é”™è¯¯ï¼Œä¸å½±å“è¿è¡Œæ—¶
        # å°è¯•ä½¿ç”¨ importlib é‡æ–°åŠ è½½æ¨¡å—
        import importlib
        if 'openai' in sys.modules:
            importlib.reload(sys.modules['openai'])
        # å†æ¬¡å°è¯•å¯¼å…¥ï¼Œè¿™æ¬¡å¿½ç•¥ç±»å‹é”™è¯¯
        import importlib.util
        from openai import OpenAI  # type: ignore
    else:
        raise
except ImportError as e:
    # å¦‚æœ Streamlit è¿˜æ²¡åˆå§‹åŒ–ï¼Œå…ˆåˆå§‹åŒ–
    if 'streamlit' in sys.modules:
        import streamlit as st
        st.error(f"ğŸ˜¿ OpenAI åº“å¯¼å…¥å¤±è´¥ï¼š{str(e)}\nè¯·å°è¯•å®‰è£…ï¼špip install openai")
        st.stop()
    else:
        raise

# --- 0. å¯†ç æ‹¦æˆªåŠŸèƒ½ ---
with st.sidebar:
    # è®¿é—®å¯†ç å¿…é¡»ä» secrets ä¸­è¯»å–ï¼›æœªé…ç½®åˆ™ç›´æ¥æŠ¥é”™å¹¶ç»ˆæ­¢
    try:
        ACCESS_PASSWORD = st.secrets["ACCESS_PASSWORD"]
    except Exception:
        st.error("âŒ æœªé…ç½®è®¿é—®å¯†é’¥ï¼Œè¯·åœ¨ Secrets ä¸­é…ç½® ACCESS_PASSWORD")
        st.stop()
    
    password = st.text_input("è®¿é—®å¯†é’¥", type="password", key="access_password")
    if password != ACCESS_PASSWORD:
        st.warning("è¿™æ˜¯ç§äººçŒ«çªï¼Œè¯·å‡ºç¤ºæš—å·ï¼ğŸš«")
        st.stop()

# --- 1. é¡µé¢é…ç½®ä¸èµ›åšæ„Ÿç¾åŒ– ---
st.set_page_config(page_title="Neko-Spirit | æœºé­‚è§‰é†’", page_icon="ğŸ®")
st.markdown("""
    <style>
    /* ================= å…¨å±€åŸºç¡€è®¾å®š ================= */
    .stApp { 
        background: linear-gradient(135deg, #050a0f 0%, #1a0d2e 50%, #0d1b2a 100%);
        color: #ffffff; /* æ”¹ä¸ºçº¯ç™½ï¼Œæé«˜æ¸…æ™°åº¦ */
        font-family: 'Microsoft YaHei', sans-serif;
    }
    
    /* è®©æ‰€æœ‰æ–‡æœ¬æ›´æ¸…æ™° - æ’é™¤ KaTeX ç›¸å…³ç±»ä»¥é¿å…æ•°å­¦å…¬å¼æ¨¡ç³Š */
    p:not(.katex):not(.katex-display):not(.katex-display *),
    button {
        font-weight: 500 !important; /* å…¨å±€åŠ ç²— */
        letter-spacing: 0.5px;
    }
    
    /* ç¡®ä¿ KaTeX æ¸²æŸ“çš„æ•°å­¦å…¬å¼æ¸…æ™° - æ’é™¤æ‰€æœ‰ KaTeX ç›¸å…³å…ƒç´  */
    .katex, .katex *, 
    [class*="katex"], 
    [class*="katex"] * {
        font-weight: normal !important;
        letter-spacing: normal !important;
    }
    
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 6rem; /* åº•éƒ¨ç•™å‡ºç©ºé—´ç»™è¾“å…¥æ¡† */
        max-width: 900px;
    }

    /* ================= æ ‡é¢˜ç‰¹æ•ˆ ================= */
    h1 {
        background: linear-gradient(45deg, #ff6b9d, #ffd6e8, #ffb3d9);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        animation: shimmer 3s ease-in-out infinite;
        font-weight: bold;
    }
    @keyframes shimmer {
        0%, 100% { filter: brightness(1); }
        50% { filter: brightness(1.3); }
    }

    /* ================= èŠå¤©æ¶ˆæ¯å®¹å™¨æ ¸å¿ƒ ================= */
    .stChatMessage {
        background: transparent !important;
        border: none !important;
        padding: 0 !important;
        margin-bottom: 1rem !important;
    }

    /* ä¿®å¤ Flex å¸ƒå±€ï¼šç¡®ä¿å¤´åƒä¸è¢«æŒ¤å‹ */
    .stChatMessage > div {
        display: flex !important;
        align-items: flex-start !important; /* é¡¶éƒ¨å¯¹é½ */
        flex-direction: row !important;
        gap: 10px !important;
    }

    /* ================= ğŸ”´ å¤´åƒç»ˆæä¿®æ­£ (Avatar Fix) ================= */
    /* 1. é”å®šå®¹å™¨å°ºå¯¸ï¼Œç¦æ­¢å‹ç¼© */
    [data-testid="stAvatar"] {
        width: 45px !important;
        height: 45px !important;
        min-width: 45px !important; /* å…³é”®ï¼šé˜²æ­¢Flexå‹ç¼© */
        flex-shrink: 0 !important;   /* å…³é”®ï¼šç¦æ­¢æ”¶ç¼© */
        flex-grow: 0 !important;
        border-radius: 8px !important;
        background: rgba(255, 255, 255, 0.1) !important;
        border: 1px solid rgba(255, 107, 157, 0.5) !important; /* è¾¹æ¡†åŠ äº® */
        overflow: hidden !important; /* ç¡®ä¿å›¾ç‰‡ä¸æº¢å‡º */
        margin: 0 !important;
    }

    /* 2. é”å®šå›¾ç‰‡/Emoji æ¸²æŸ“æ–¹å¼ */
    [data-testid="stAvatar"] img, 
    [data-testid="stAvatar"] div {
        width: 100% !important;
        height: 100% !important;
        object-fit: cover !important; /* å…³é”®ï¼šè£å‰ªè€Œéå˜å½¢ */
        display: flex !important;
        align-items: center;
        justify-content: center;
        font-size: 24px !important; /* Emoji å¤§å° */
    }

    /* 3. é’ˆå¯¹ä¸åŒè§’è‰²çš„å¤´åƒä½ç½®å¾®è°ƒ */
    .stChatMessage[data-testid="user"] {
        flex-direction: row-reverse !important; /* ç”¨æˆ·æ¶ˆæ¯åè½¬å¸ƒå±€ */
    }
    
    /* ç”¨æˆ·å¤´åƒå¾®è°ƒ */
    .stChatMessage[data-testid="user"] [data-testid="stAvatar"] {
        margin-left: 8px !important;
    }
    
    /* æœºå™¨äººå¤´åƒå¾®è°ƒ */
    .stChatMessage[data-testid="assistant"] [data-testid="stAvatar"] {
        margin-right: 8px !important;
    }

    /* ================= æ°”æ³¡æ ·å¼ (é«˜å¯¹æ¯”åº¦ç‰ˆ) ================= */
    /* æ¶ˆæ¯å†…å®¹æ–‡æœ¬ */
    .stChatMessage .stMarkdown {
        color: #ffffff !important; /* å¼ºåˆ¶ç™½è‰²æ–‡å­— */
        font-size: 16px !important; /* ç¨å¾®è°ƒå¤§å­—ä½“ */
        line-height: 1.6 !important;
        text-shadow: 0 1px 2px rgba(0,0,0,0.5); /* æ–‡å­—é˜´å½±å¢åŠ å¯è¯»æ€§ */
    }
    
    /* æ¶ˆæ¯å†…å®¹å®¹å™¨é€šç”¨ */
    .stChatMessage > div > div:nth-child(2) {
        max-width: 80% !important;
        padding: 12px 18px !important;
        border-radius: 12px !important;
        box-shadow: 0 4px 6px rgba(0,0,0,0.3);
    }

    /* AI æ°”æ³¡ - å¢åŠ ä¸é€æ˜åº¦ */
    .stChatMessage[data-testid="assistant"] > div > div:nth-child(2) {
        background: rgba(30, 30, 40, 0.8) !important; /* æ·±è‰²èƒŒæ™¯è¡¬æ‰˜ç™½å­— */
        border: 1px solid rgba(255, 214, 232, 0.3);
        border-top-left-radius: 2px !important; /* å°è§’æ•ˆæœ */
    }

    /* ç”¨æˆ· æ°”æ³¡ - å¢åŠ ä¸é€æ˜åº¦ */
    .stChatMessage[data-testid="user"] > div > div:nth-child(2) {
        background: linear-gradient(135deg, rgba(255, 107, 157, 0.8), rgba(255, 71, 133, 0.8)) !important;
        border: 1px solid rgba(255, 255, 255, 0.2);
        border-top-right-radius: 2px !important; /* å°è§’æ•ˆæœ */
    }

    /* ================= è¾“å…¥æ¡†ç¾åŒ– ================= */
    div[data-testid="stChatInputContainer"] {
        background: rgba(13, 27, 42, 0.95) !important;
        backdrop-filter: blur(10px);
        border-top: 1px solid rgba(255, 107, 157, 0.2);
        padding-bottom: 20px;
    }
    
    div[data-testid="stChatInputTextArea"] textarea {
        background-color: rgba(0, 0, 0, 0.3) !important;
        color: white !important;
        border: 1px solid rgba(255, 107, 157, 0.5) !important;
        font-weight: bold !important;
    }
    
    div[data-testid="stChatInputTextArea"] textarea:focus {
        border-color: #ff6b9d !important;
        box-shadow: 0 0 10px rgba(255, 107, 157, 0.2) !important;
    }

    /* ================= æ»šåŠ¨æ¡ä¸æ‚é¡¹ ================= */
    ::-webkit-scrollbar { width: 6px; }
    ::-webkit-scrollbar-thumb { background: #ff6b9d; border-radius: 3px; }
    ::-webkit-scrollbar-track { background: transparent; }
    
/* ================= ä»£ç å—ç»ˆæä¼˜åŒ– ================= */
    /* 1. é’ˆå¯¹è¡Œå†…ä»£ç  (æ¯”å¦‚ `print`) */
    code {
        background: rgba(255, 107, 157, 0.15) !important;
        color: #ffb3d9 !important; /* ç²‰è‰²æ–‡å­— */
        border-radius: 4px;
        padding: 2px 6px;
        font-family: 'Consolas', monospace;
    }

    /* 2. é’ˆå¯¹å¤§æ®µä»£ç å— (```python ... ```) */
    /* è¿™é‡Œçš„ pre æ˜¯ä»£ç å—çš„å¤–å±‚å®¹å™¨ */
    .stMarkdown pre {
        background-color: #1a1a1a !important; /* çº¯æ·±ç°èƒŒæ™¯ï¼Œå¯¹æ¯”åº¦æ›´ä½æ›´æŠ¤çœ¼ */
        border: 1px solid rgba(255, 107, 157, 0.2) !important;
        border-radius: 10px !important;
    }

    /* 3. å…³é”®é­”æ³•ï¼šé™ä½ä»£ç é«˜äº®çš„â€œåˆºçœ¼åº¦â€ */
    .stMarkdown pre code {
        font-family: 'Consolas', 'Fira Code', monospace !important;
        /* filter: saturate(50%);  <-- è¿™è¡Œä»£ç ä¼šæŠŠé¢œè‰²çš„é²œè‰³åº¦ç æ‰ä¸€åŠ */
        filter: saturate(0.6) brightness(1.2) !important; 
        background-color: transparent !important; /* ç¡®ä¿èƒŒæ™¯ä¸å†²çª */
    }
    </style>
""", unsafe_allow_html=True)

# --- 2. API é…ç½® (ä» secrets è¯»å–) ---
try:
    # ä» Streamlit secrets è¯»å– API Key
    SJTU_API_KEY = st.secrets["SJTU_API_KEY"]
    HF_API_TOKEN = st.secrets["HF_API_TOKEN"]
    SILICON_API_KEY = st.secrets["SILICON_API_KEY"]
    TAVILY_API_KEY = st.secrets.get("TAVILY_API_KEY", "")  # å¯é€‰ï¼Œæœ‰é»˜è®¤å€¼
except Exception as e:
    st.error("âš ï¸ æœªæ£€æµ‹åˆ°å¯†é’¥é…ç½®ï¼è¯·åœ¨ `.streamlit/secrets.toml` ä¸­é…ç½® API Keyã€‚\n\n"
             "é…ç½®ç¤ºä¾‹ï¼š\n"
             "```toml\n"
             "SJTU_API_KEY = \"your-key-here\"\n"
             "HF_API_TOKEN = \"your-token-here\"\n"
             "SILICON_API_KEY = \"your-key-here\"\n"
             "TAVILY_API_KEY = \"your-key-here\"\n"
             "```\n\n"
             f"é”™è¯¯è¯¦æƒ…ï¼š{str(e)}")
    st.stop()

# API åŸºç¡€ URL é…ç½®ï¼ˆä¸éœ€è¦ä¿å¯†ï¼‰
SJTU_BASE_URL = "https://models.sjtu.edu.cn/api/v1"
MODEL_NAME = "deepseek-v3"  # <--- è¿™é‡Œæ”¹æˆäº†å…¨å°å†™ï¼Œä¿®å¤ 401 æŠ¥é”™
VISION_MODEL_NAME = "qwen3vl"  # è§†è§‰è¯†åˆ«æ¨¡å‹

# --- ç»˜ç”»åŠŸèƒ½é…ç½® ---
HF_API_URL = "https://router.huggingface.co/hf-inference/models/black-forest-labs/FLUX.1-schnell"

# --- SiliconFlow é…ç½® (å…¨æ ˆå›½äº§è¯­éŸ³) ---
SILICON_BASE_URL = "https://api.siliconflow.cn/v1"

# å»¶è¿Ÿåˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œé¿å…ç±»å‹æ³¨è§£é”™è¯¯
def get_openai_client():
    """è·å– OpenAI å®¢æˆ·ç«¯ï¼Œå»¶è¿Ÿåˆå§‹åŒ–ä»¥é¿å…ç±»å‹é”™è¯¯"""
    if "openai_client" not in st.session_state:
        try:
            st.session_state.openai_client = OpenAI(api_key=SJTU_API_KEY, base_url=SJTU_BASE_URL)
        except (TypeError, AttributeError) as e:
            # å¦‚æœé‡åˆ° Generic ç±»å‹é”™è¯¯æˆ–å…¶ä»–é”™è¯¯ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–
            error_msg = str(e)
            if "Generic" in error_msg or "type variables" in error_msg:
                # è¿™æ˜¯ç±»å‹æ³¨è§£é”™è¯¯ï¼Œé€šå¸¸ä¸å½±å“å®é™…è¿è¡Œ
                # å°è¯•ç›´æ¥åˆ›å»ºå®¢æˆ·ç«¯ï¼Œå¿½ç•¥ç±»å‹é”™è¯¯
                try:
                    st.session_state.openai_client = OpenAI(api_key=SJTU_API_KEY, base_url=SJTU_BASE_URL)
                except:
                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                    st.error(f"ğŸ˜¿ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼š{error_msg}\n\nè¿™å¯èƒ½æ˜¯å› ä¸º openai åº“ç‰ˆæœ¬é—®é¢˜ã€‚\nè¯·å°è¯•ï¼špip install --upgrade openai")
                    st.stop()
            else:
                st.error(f"ğŸ˜¿ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼š{error_msg}")
                st.stop()
    return st.session_state.openai_client

# --- æ•°å­¦å…¬å¼æ ¼å¼åŒ–å‡½æ•° ---
def format_deepseek_math(text):
    """
    å°† DeepSeek å¸¸ç”¨çš„ LaTeX å®šç•Œç¬¦è½¬æ¢ä¸º Streamlit æ”¯æŒçš„æ ¼å¼
    """
    if not text:
        return text
    
    # æ›¿æ¢å—çº§å…¬å¼ \[ ... \] ä¸º $$ ... $$
    text = re.sub(r'\\\[(.*?)\\\]', r'$$\1$$', text, flags=re.DOTALL)
    
    # æ›¿æ¢è¡Œå†…å…¬å¼ \( ... \) ä¸º $ ... $
    text = re.sub(r'\\\((.*?)\\\)', r'$\1$', text, flags=re.DOTALL)
    
    # ä¿®å¤å¯èƒ½å‡ºç°çš„è½¬ä¹‰ç¾å…ƒç¬¦å·
    text = text.replace(r'\$', '$')
    
    return text

# --- R1 æ€è€ƒè¿‡ç¨‹è§£æå‡½æ•° ---
def parse_r1_response(response_text):
    """
    è§£æ DeepSeek-R1 çš„å›å¤ï¼Œåˆ†ç¦»æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆ
    è¿”å›: (thinking_content, final_answer)
    """
    # R1 æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹é€šå¸¸ç”¨ <think> å’Œ </think> æ ‡ç­¾åŒ…è£¹
    think_pattern = r'<think>(.*?)</think>'
    matches = re.findall(think_pattern, response_text, re.DOTALL)
    
    if matches:
        # æå–æ€è€ƒè¿‡ç¨‹
        thinking_content = '\n\n'.join(matches)
        # ç§»é™¤æ€è€ƒæ ‡ç­¾ï¼Œè·å–æœ€ç»ˆç­”æ¡ˆ
        final_answer = re.sub(think_pattern, '', response_text, flags=re.DOTALL).strip()
        return thinking_content, final_answer
    else:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ€è€ƒæ ‡ç­¾ï¼Œè¿”å›åŸæ–‡æœ¬ä½œä¸ºç­”æ¡ˆ
        return None, response_text

# --- è§†è§‰è¯†åˆ«è¾…åŠ©å‡½æ•° ---
def get_image_base64(image_source):
    """
    å°†å›¾ç‰‡è½¬æ¢ä¸ºBase64ç¼–ç ï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼
    ä¸¥æ ¼æŒ‰ç…§æ ‡å‡†ï¼šå‹ç¼©åˆ°æœ€å¤§è¾¹é•¿1024pxï¼Œè½¬ä¸ºJPEGæ ¼å¼ï¼Œquality=80
    """
    if not PIL_AVAILABLE:
        raise ImportError("Pillow (PIL) æœªå®‰è£…ï¼Œæ— æ³•å¤„ç†å›¾ç‰‡ã€‚è¯·å®‰è£…: pip install Pillow")
    
    try:
        # 1. æ‰“å¼€å›¾ç‰‡ï¼ˆæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼ï¼‰
        if isinstance(image_source, Image.Image):
            img = image_source.copy()
        else:
            # å¤„ç† file_uploader è¿”å›çš„æ–‡ä»¶å¯¹è±¡æˆ–å…¶ä»–æ–‡ä»¶å¯¹è±¡
            if hasattr(image_source, 'seek'):
                image_source.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
            img = Image.open(image_source)
        
        # 2. æ£€æŸ¥å¹¶è·å–åŸå§‹å°ºå¯¸
        original_size = img.size
        max_dimension = max(original_size)
        
        # 3. è½¬æ¢ä¸ºRGBæ ¼å¼ï¼ˆå»æ‰PNGçš„é€æ˜é€šé“ï¼Œé˜²æ­¢æ ¼å¼å…¼å®¹é—®é¢˜ï¼‰
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # 4. å‹ç¼©å›¾ç‰‡ï¼šresizeåˆ°æœ€å¤§è¾¹é•¿ä¸è¶…è¿‡1024px
        if max_dimension > 1024:
            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
            scale = 1024 / max_dimension
            new_size = (int(original_size[0] * scale), int(original_size[1] * scale))
            img = img.resize(new_size, Image.Resampling.LANCZOS)
        
        # 5. ä¿å­˜ä¸ºJPEGæ ¼å¼ï¼Œå‹ç¼©è´¨é‡è®¾ä¸ºquality=80
        buffered = BytesIO()
        img.save(buffered, format="JPEG", quality=80)
        
        # 6. è½¬æ¢ä¸ºBase64å­—ç¬¦ä¸²ï¼ˆä¸åŒ…å«å‰ç¼€ï¼Œå‰ç¼€åœ¨è°ƒç”¨å¤„æ·»åŠ ï¼‰
        img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
        return img_str
        
    except Exception as e:
        st.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥ï¼š{str(e)}")
        raise

def decode_base64_image(base64_string):
    """å°†Base64å­—ç¬¦ä¸²è§£ç ä¸ºPIL Imageå¯¹è±¡"""
    if not PIL_AVAILABLE:
        return None
    
    try:
        # ç§»é™¤ data:image/...;base64, å‰ç¼€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if isinstance(base64_string, str):
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¹¶ç§»é™¤å‰ç¼€
            base64_string = re.sub(r'^data:image/[^;]+;base64,', '', base64_string)
            # è§£ç Base64å­—ç¬¦ä¸²
            decoded_data = base64.b64decode(base64_string)
            # è½¬æ¢ä¸ºPIL Image
            image = Image.open(io.BytesIO(decoded_data))
            return image
        return None
    except Exception as e:
        st.warning(f"Base64è§£ç å¤±è´¥ï¼š{str(e)}")
        return None

def get_image_for_display(image_source):
    """è·å–ç”¨äºæ˜¾ç¤ºçš„å›¾ç‰‡å¯¹è±¡ï¼ˆPIL Imageï¼‰"""
    # å¦‚æœå·²ç»æ˜¯ PIL Imageï¼Œç›´æ¥è¿”å›
    if isinstance(image_source, Image.Image):
        return image_source
    
    # å¦‚æœæ˜¯Base64å­—ç¬¦ä¸²ï¼Œå…ˆè§£ç 
    if isinstance(image_source, str):
        decoded_img = decode_base64_image(image_source)
        if decoded_img:
            return decoded_img
        return None
    
    # å¦‚æœæ˜¯æ–‡ä»¶å¯¹è±¡ï¼Œæ‰“å¼€å®ƒ
    if PIL_AVAILABLE:
        try:
            return Image.open(image_source)
        except:
            return None
    return None

def recognize_image(image_base64):
    """
    ä½¿ç”¨qwen3vlæ¨¡å‹è¯†åˆ«å›¾ç‰‡å†…å®¹
    ä¸¥æ ¼æŒ‰ç…§æ ‡å‡†ï¼šBase64å­—ç¬¦ä¸²å¿…é¡»åŠ ä¸Šå‰ç¼€ data:image/jpeg;base64,
    """
    try:
        # ç¡®ä¿Base64å­—ç¬¦ä¸²åŒ…å«æ ‡å‡†å‰ç¼€
        if not image_base64.startswith("data:image/jpeg;base64,"):
            image_url = f"data:image/jpeg;base64,{image_base64}"
        else:
            image_url = image_base64
        
        # æ„å»ºæ¶ˆæ¯ï¼ŒåŒ…å«å›¾ç‰‡ï¼ˆä¸¥æ ¼æŒ‰ç…§APIè¦æ±‚çš„ç»“æ„ï¼‰
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚å¦‚æœå›¾ç‰‡é‡Œæœ‰æ–‡å­—ï¼Œè¯·åŠ¡å¿…å®Œæ•´æå–å‡ºæ¥ã€‚"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": image_url  # å¿…é¡»å¸¦å‰ç¼€ data:image/jpeg;base64,
                        }
                    }
                ]
            }
        ]
        
        # è°ƒç”¨è§†è§‰æ¨¡å‹
        client = get_openai_client()
        completion = client.chat.completions.create(
            model=VISION_MODEL_NAME,
            messages=messages,
            max_tokens=1000,
            timeout=120.0  # <--- æ–°å¢ï¼šç»™è§†è§‰è¯†åˆ« 2 åˆ†é’Ÿçš„ç­‰å¾…æ—¶é—´
        )
        
        description = completion.choices[0].message.content
        return description
    except Exception as e:
        return f"å›¾ç‰‡è¯†åˆ«å¤±è´¥ï¼š{str(e)}"

# --- è¯­éŸ³è¯†åˆ«åŠŸèƒ½ (STT) ---
def transcribe_audio(audio_bytes):
    """ä½¿ç”¨ SenseVoiceSmall è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
    try:
        client = OpenAI(api_key=SILICON_API_KEY, base_url=SILICON_BASE_URL)
        
        # âš ï¸ å…³é”®ç‚¹ï¼šaudio_bytes æ˜¯ st.audio_input è¿”å›çš„å¯¹è±¡
        # å°† BytesIO æŒ‡é’ˆé‡ç½®åˆ°å¼€å¤´ (éå¸¸é‡è¦!)
        audio_bytes.seek(0)
        
        # æ˜¾å¼æŒ‡å®šæ–‡ä»¶åå’ŒMIMEç±»å‹
        transcription = client.audio.transcriptions.create(
            file=("speech.wav", audio_bytes, "audio/wav"),  # æ˜¾å¼æŒ‡å®šæ–‡ä»¶åå’ŒMIMEç±»å‹
            model="FunAudioLLM/SenseVoiceSmall",
            response_format="json"
        )
        return transcription.text, None
    except Exception as e:
        return None, f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"

# --- ä¼˜åŒ–åçš„è¯­éŸ³åˆæˆåŠŸèƒ½ (TTS) ---
def text_to_speech(text):
    """
    ä½¿ç”¨ CosyVoice2 è¿›è¡Œè¯­éŸ³åˆæˆ (BellaéŸ³è‰²-å¯çˆ±é£)
    
    æ³¨æ„ï¼šæ­¤å‡½æ•°æ¥æ”¶çš„ text åº”è¯¥å·²ç»æ˜¯æ¸…æ´—è¿‡çš„æ–‡æœ¬ï¼ˆç”± clean_text_for_speech å¤„ç†ï¼‰
    åªè´Ÿè´£è°ƒç”¨ TTS APIï¼Œä¸åšé¢å¤–çš„æ–‡æœ¬å¤„ç†
    """
    try:
        client = OpenAI(api_key=SILICON_API_KEY, base_url=SILICON_BASE_URL)
        
        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æ–‡æœ¬ï¼ˆå·²ç»åœ¨ play_ai_voice ä¸­æ¸…æ´—è¿‡ï¼‰
        # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
        if not text or not text.strip():
            return None
        
        response = client.audio.speech.create(
            model="FunAudioLLM/CosyVoice2-0.5B",
            voice="FunAudioLLM/CosyVoice2-0.5B:bella", # <--- å…³é”®ï¼šåˆ‡æ¢ä¸º Bella
            input=text.strip(),  # åªå»é™¤é¦–å°¾ç©ºç™½ï¼Œä¸åšå…¶ä»–å¤„ç†
            response_format="mp3"
        )
        
        mp3_fp = BytesIO(response.content)
        mp3_fp.seek(0)
        return mp3_fp
    except Exception as e:
        st.error(f"ğŸ˜¿ è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}")
        return None

def clean_text_for_speech(text, is_english_mode=False):
    """
    æ¸…æ´—æ–‡æœ¬ï¼Œå»é™¤ä¸é€‚åˆå‘éŸ³çš„å†…å®¹
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        is_english_mode: æ˜¯å¦ä¸ºè‹±è¯­å£è¯­æ¨¡å¼
    
    Returns:
        æ¸…æ´—åçš„æ–‡æœ¬
    """
    if not text:
        return ""
    
    # 1. å»é™¤ Markdown ç¬¦å·
    clean_text = re.sub(r'[*#`~<>\[\]()]', '', text)
    
    # 2. å¦‚æœæ˜¯è‹±è¯­å£è¯­æ¨¡å¼ï¼Œè¿›è¡Œç‰¹æ®Šå¤„ç†
    if is_english_mode:
        # å»é™¤è¯­æ°”è¯ï¼ˆå–µã€Meowã€Nyaã€å‘¼å™œç­‰ï¼‰
        meow_patterns = [
            r'[å–µå–µ~]+',  # ä¸­æ–‡å–µ
            r'\b[Mm]eow\b',  # Meow
            r'\b[Nn]ya\b',  # Nya
            r'[å‘¼å™œ~]+',  # å‘¼å™œå£°
            r'[~]+',  # å•ç‹¬çš„æ³¢æµªå·
        ]
        for pattern in meow_patterns:
            clean_text = re.sub(pattern, '', clean_text, flags=re.IGNORECASE)
        
        # å»é™¤ä¸­æ–‡å†…å®¹ï¼ˆåŒ…æ‹¬ä¸­æ–‡å­—ç¬¦å’Œå¸¸è§çš„ä¸­æ–‡æ ‡ç‚¹ï¼‰
        # åŒ¹é…ä¸­æ–‡å­—ç¬¦ã€ä¸­æ–‡æ ‡ç‚¹ï¼Œä»¥åŠå®ƒä»¬å‘¨å›´çš„ç©ºç™½
        clean_text = re.sub(r'[\u4e00-\u9fff\u3000-\u303f\uff00-\uffef]+[ï¼Œã€‚ï¼ï¼Ÿï¼šï¼›ã€]*', '', clean_text)
        
        # å»é™¤å¸¸è§çš„ä¸­æ–‡æç¤ºè¯ï¼ˆå¦‚"æ¸©æŸ”åœ°æŒ‡å‡º"ã€"æ­£ç¡®ç¤ºèŒƒ"ç­‰ï¼‰
        chinese_phrases = [
            r'æ¸©æŸ”åœ°æŒ‡å‡º',
            r'æ­£ç¡®ç¤ºèŒƒ',
            r'å…ˆç”¨ä¸­æ–‡',
            r'ç„¶åç»™å‡º',
        ]
        for phrase in chinese_phrases:
            clean_text = re.sub(phrase, '', clean_text, flags=re.IGNORECASE)
    
    # 3. å»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    clean_text = re.sub(r'\s+', ' ', clean_text)
    
    # 4. å»é™¤é¦–å°¾ç©ºç™½
    clean_text = clean_text.strip()
    
    return clean_text

def play_ai_voice(text):
    """åŒæ­¥åŒ…è£…å™¨ï¼Œå¸¦åŠ è½½æç¤º"""
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ºè‹±è¯­å£è¯­æ¨¡å¼
        is_english_mode = st.session_state.get("practice_mode", False)
        
        # ä½¿ç”¨å¢å¼ºçš„æ–‡æœ¬æ¸…æ´—å‡½æ•°
        clean_text = clean_text_for_speech(text, is_english_mode=is_english_mode)
        
        if not clean_text:
            return

        # ã€å…³é”®ä¿®æ”¹ã€‘å¢åŠ åŠ è½½åŠ¨ç”»
        with st.spinner("ğŸ”Š å°å–µæ­£åœ¨ç”Ÿæˆè¯­éŸ³..."):
            audio_fp = text_to_speech(clean_text)
        
        if audio_fp:
            st.audio(audio_fp, format='audio/mp3', autoplay=True)
            
    except Exception as e:
        st.error(f"ğŸ˜¿ è¯­éŸ³æ’­æ”¾å¤±è´¥: {str(e)}")

# --- è”ç½‘æœç´¢åŠŸèƒ½å‡½æ•° ---
    """
    ä½¿ç”¨ Tavily API è¿›è¡Œè”ç½‘æœç´¢
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢å­—ç¬¦ä¸²
    
    Returns:
        str æˆ– None: æ•´ç†å¥½çš„æœç´¢ç»“æœå­—ç¬¦ä¸²ï¼Œå¦‚æœæœç´¢å¤±è´¥è¿”å› None
    """
    # Tavily API é…ç½®ï¼ˆä»å…¨å±€å˜é‡è¯»å–ï¼Œå·²åœ¨é¡¶éƒ¨ä» secrets åŠ è½½ï¼‰
    api_key = TAVILY_API_KEY
def perform_web_search(query):
    """
    ä½¿ç”¨ Tavily API è¿›è¡Œè”ç½‘æœç´¢ (äº‘ç«¯ä¿®æ­£ç‰ˆ - å·²ç§»é™¤ä»£ç†)
    """
    # Tavily API é…ç½®
    api_key = TAVILY_API_KEY
    if not api_key:
        st.warning("âš ï¸ Tavily API Key æœªé…ç½®ï¼Œæœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
        return None
    url = "https://api.tavily.com/search"
    
    # æ„å»ºè¯·æ±‚ä½“
    payload = {
        "api_key": api_key,
        "query": query,
        "search_depth": "basic",
        "include_answer": True,
        "max_results": 5
    }
    
    # âŒ å·²åˆ é™¤ proxies ä»£ç†è®¾ç½®ï¼Œäº‘ç«¯ç›´è¿
    
    try:
        # ç›´æ¥å‘é€è¯·æ±‚ï¼Œä¸å¸¦ proxies å‚æ•°
        response = requests.post(url, json=payload, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            results = data.get("results", [])
            summary = ""
            for i, res in enumerate(results, 1):
                summary += f"{i}. ã€{res.get('title')}ã€‘\n{res.get('content')}\n\n"
            return summary if summary else None
        else:
            print(f"âŒ Tavily æœç´¢å¤±è´¥: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚æŠ¥é”™: {e}")
        return None

# --- æ–‡æ¡£å¤„ç†åŠŸèƒ½å‡½æ•° ---
def extract_text_from_file(uploaded_file):
    """
    ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
    
    æ”¯æŒæ ¼å¼ï¼š
    - PDF (.pdf) - ä½¿ç”¨ pdfplumber
    - Word æ–‡æ¡£ (.docx) - ä½¿ç”¨ python-docx
    - æ–‡æœ¬æ–‡ä»¶ (.txt, .md, .py) - ç›´æ¥è¯»å–
    
    Args:
        uploaded_file: Streamlit ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
    
    Returns:
        str: æå–å‡ºçš„å®Œæ•´æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    if uploaded_file is None:
        return None
    
    try:
        # è·å–æ–‡ä»¶æ‰©å±•å
        file_name = uploaded_file.name.lower()
        
        # å¤„ç† PDF æ–‡ä»¶
        if file_name.endswith('.pdf'):
            if not PDFPLUMBER_AVAILABLE:
                st.error("ğŸ˜¿ PDF å¤„ç†éœ€è¦ pdfplumber åº“ï¼Œè¯·å®‰è£…ï¼špip install pdfplumber")
                return None
            
            # ä½¿ç”¨ pdfplumber æå–æ–‡æœ¬
            text_content = ""
            # å°†æ–‡ä»¶å¯¹è±¡è½¬æ¢ä¸º BytesIOï¼ˆpdfplumber éœ€è¦ï¼‰
            file_bytes = BytesIO(uploaded_file.read())
            uploaded_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
            
            with pdfplumber.open(file_bytes) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text_content += page_text + "\n"
            
            return text_content.strip() if text_content else None
        
        # å¤„ç† Word æ–‡æ¡£ (.docx)
        elif file_name.endswith('.docx'):
            if not DOCX_AVAILABLE or docx is None:
                st.error("ğŸ˜¿ Word æ–‡æ¡£å¤„ç†éœ€è¦ python-docx åº“ï¼Œè¯·å®‰è£…ï¼špip install python-docx")
                return None
            
            # ä½¿ç”¨ python-docx æå–æ–‡æœ¬
            text_content = ""
            # å°†æ–‡ä»¶å¯¹è±¡è½¬æ¢ä¸º BytesIOï¼ˆdocx.Document éœ€è¦ï¼‰
            file_bytes = BytesIO(uploaded_file.read())
            uploaded_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
            
            try:
                doc = docx.Document(file_bytes)
                # éå†æ‰€æœ‰æ®µè½æå–æ–‡æœ¬
                for paragraph in doc.paragraphs:
                    if paragraph.text:
                        text_content += paragraph.text + "\n"
                
                return text_content.strip() if text_content else None
            except Exception as e:
                st.error(f"ğŸ˜¿ Word æ–‡æ¡£è§£æå¤±è´¥ï¼š{str(e)}")
                return None
        
        # å¤„ç†æ–‡æœ¬æ–‡ä»¶ (.txt, .md, .py)
        elif file_name.endswith(('.txt', '.md', '.py')):
            # å°è¯•å¤šç§ç¼–ç æ ¼å¼
            encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1']
            for encoding in encodings:
                try:
                    uploaded_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                    content = uploaded_file.read().decode(encoding)
                    return content
                except UnicodeDecodeError:
                    continue
            
            # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯
            st.error("ğŸ˜¿ æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç æ ¼å¼")
            return None
        
        else:
            st.error(f"ğŸ˜¿ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š{file_name.split('.')[-1]}")
            return None
            
    except Exception as e:
        st.error(f"ğŸ˜¿ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š{str(e)}")
        return None

# --- ä¿®å¤åçš„æ²™ç®± (ä¿®å¤ä½œç”¨åŸŸéš”ç¦»å¯¼è‡´çš„ NameError) ---
def execute_python_code(code_str):
    """
    å®‰å…¨æ‰§è¡Œ Python ä»£ç 
    
    ä¿®å¤ NameError é—®é¢˜ï¼šç¡®ä¿ exec çš„ globals å’Œ locals ç»Ÿä¸€ï¼Œä½¿å‡½æ•°é—´å¯ä»¥äº’ç›¸è°ƒç”¨
    
    Args:
        code_str: è¦æ‰§è¡Œçš„ Python ä»£ç å­—ç¬¦ä¸²
    
    Returns:
        str: æ‰§è¡ŒæˆåŠŸçš„ stdout å­—ç¬¦ä¸²ï¼Œæˆ–è€…é”™è¯¯/è¶…æ—¶ä¿¡æ¯çš„å­—ç¬¦ä¸²
    """
    import math
    import random as random_module
    from datetime import datetime as datetime_module
    import re as re_module
    import json as json_module
    
    # å…è®¸å¯¼å…¥çš„æ¨¡å—ç™½åå•
    allowed_modules = {'math', 'random', 'datetime', 're', 'json', 'numpy', 'np'}
    
    # è‡ªå®šä¹‰å®‰å…¨å¯¼å…¥å‡½æ•°
    import builtins
    original_import = builtins.__import__
    
    def secure_import(name, globals=None, locals=None, fromlist=(), level=0):
        # å¤„ç† numpy çš„åˆ«åæƒ…å†µ
        check_name = name.split('.')[0]
        if check_name in allowed_modules:
            return original_import(name, globals, locals, fromlist, level)
        raise ImportError(f"âŒ å®‰å…¨é™åˆ¶ï¼šç¯å¢ƒä¸æ”¯æŒæ¨¡å— '{name}' (ä»…æ”¯æŒæ ‡å‡†åº“ + numpy)")
    
    # æ„é€ å®‰å…¨çš„å…¨å±€ç¯å¢ƒ
    # å…³é”®ä¿®æ”¹ï¼šè¿™å°†ä½œä¸ºå”¯ä¸€çš„æ‰§è¡Œä¸Šä¸‹æ–‡
    execution_context = {
        '__builtins__': {
            '__import__': secure_import,
            'print': print,
            'range': range,
            'len': len,
            'int': int,
            'float': float,
            'str': str,
            'list': list,
            'dict': dict,
            'set': set,
            'tuple': tuple,
            'sum': sum,
            'min': min,
            'max': max,
            'abs': abs,
            'round': round,
            'sorted': sorted,
            'enumerate': enumerate,
            'zip': zip,
            'map': map,
            'filter': filter,
            'bool': bool,
            'all': all,
            'any': any,
            'pow': pow, # è¡¥ä¸Š pow
        },
        'math': math,
        'random': random_module,
        'datetime': datetime_module,
        're': re_module,
        'json': json_module,
    }
    
    # å°è¯•å¯¼å…¥ numpy
    try:
        import numpy
        execution_context['numpy'] = numpy
        execution_context['np'] = numpy
    except ImportError:
        pass
    
    # ç§»é™¤ Pandas çš„å°è¯•
    
    # æ˜ç¡®ç¦æ­¢çš„å±é™©å‡½æ•°å…³é”®è¯
    forbidden_keywords = ['open', 'input', 'eval', 'exec', 'os.', 'sys.', 'subprocess', 'pandas']
    
    code_lower = code_str.lower()
    for kw in forbidden_keywords:
        if kw in code_lower and kw not in ['pandas']: 
             pass
    
    # ä½¿ç”¨ StringIO æ•è·è¾“å‡º
    output_buffer = io.StringIO()
    
    # è¶…æ—¶æ§åˆ¶
    execution_result = {'output': '', 'error': None, 'timeout': False}
    
    def run_code():
        try:
            with contextlib.redirect_stdout(output_buffer):
                with contextlib.redirect_stderr(output_buffer):
                    # âœ¨ æ ¸å¿ƒä¿®å¤ âœ¨ï¼šglobals å’Œ locals ä½¿ç”¨åŒä¸€ä¸ªå­—å…¸
                    # è¿™æ · is_prime å®šä¹‰åï¼Œfind_prime_pairs å°±èƒ½æ‰¾åˆ°å®ƒäº†ï¼
                    exec(code_str, execution_context, execution_context)
            execution_result['output'] = output_buffer.getvalue()
        except Exception as e:
            execution_result['error'] = str(e)
    
    thread = threading.Thread(target=run_code)
    thread.daemon = True
    thread.start()
    thread.join(timeout=5.0)
    
    if thread.is_alive():
        return "âŒ æ‰§è¡Œè¶…æ—¶ï¼šä»£ç è¿è¡Œè¶…è¿‡ 5 ç§’"
    
    if execution_result['error']:
        return f"âŒ æ‰§è¡Œé”™è¯¯ï¼š{execution_result['error']}"
    else:
        output = execution_result['output'].strip()
        return output if output else "âœ… ä»£ç æ‰§è¡ŒæˆåŠŸï¼ˆæ— è¾“å‡ºï¼‰"

# --- å‡çº§ç‰ˆæ•°å­¦è®¡ç®—å™¨ (æ”¯æŒåŸºç¡€æ•°æ®ç»“æ„) ---
def evaluate_math_expression(text):
    """
    æŸ¥æ‰¾æ–‡æœ¬ä¸­çš„ <<CALC: ç®—å¼>> æ ‡è®°ï¼Œè®¡ç®—å¹¶æ›¿æ¢
    
    å¢å¼ºç‰ˆï¼šæ”¯æŒ range, list, sum ç­‰åŸºç¡€æ“ä½œ
    
    Args:
        text: åŒ…å« <<CALC: ...>> æ ‡è®°çš„æ–‡æœ¬
    
    Returns:
        str: å¤„ç†åçš„æ–‡æœ¬ï¼Œæ‰€æœ‰æ ‡è®°éƒ½è¢«è®¡ç®—ç»“æœæ›¿æ¢
    """
    import math
    
    # å¢å¼ºçš„å®‰å…¨ä½œç”¨åŸŸ
    safe_scope = {
        'math': math,
        '__builtins__': {
            'abs': abs, 'round': round, 'min': min, 'max': max, 'sum': sum, 'pow': pow,
            'range': range, 'list': list, 'int': int, 'float': float, 'str': str,
            'len': len, 'set': set, 'tuple': tuple, 'sorted': sorted, 'enumerate': enumerate
        }
    }
    
    calc_pattern = r'<<CALC:\s*(.*?)\s*>>'
    matches = re.findall(calc_pattern, text)
    
    if not matches:
        return text
    
    result_text = text
    for expression in matches:
        try:
            # è®¡ç®—è¡¨è¾¾å¼
            result = eval(expression, safe_scope, {})
            # æ ¼å¼åŒ–è¾“å‡º
            if isinstance(result, (int, float)):
                result_str = f"{result:.4f}".rstrip('0').rstrip('.')
            else:
                result_str = str(result)
            result_text = result_text.replace(f"<<CALC: {expression}>>", result_str, 1)
        except Exception as e:
            result_text = result_text.replace(f"<<CALC: {expression}>>", f"[è®¡ç®—é”™è¯¯: {str(e)}]", 1)
    
    return result_text

# --- è¾…åŠ©å‡½æ•°ï¼šè·å–å†å²ä¸Šä¸‹æ–‡ ---
def get_recent_chat_history():
    """
    ä» st.session_state.messages ä¸­è¯»å–æœ€è¿‘çš„ 3 è½®å¯¹è¯ï¼ˆè·³è¿‡ç³»ç»Ÿæ¶ˆæ¯ï¼‰
    
    Returns:
        str: æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ "User: ...\nAssistant: ..."ï¼‰ï¼Œå¦‚æœæ²¡æœ‰å†å²åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if "messages" not in st.session_state:
        return ""
    
    # è¿‡æ»¤æ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œåªä¿ç•™ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯
    # ã€å…³é”®ä¿®å¤ã€‘ä¿ç•™åŒ…å« [ç³»ç»Ÿè§†è§‰ä¿¡å·] çš„ system æ¶ˆæ¯
    non_system_messages = []
    for msg in st.session_state.messages:
        # ä¿ç•™ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯
        if msg.get("role") != "system":
            non_system_messages.append(msg)
        # ã€å…³é”®ä¿®å¤ã€‘å¦‚æœæ˜¯è§†è§‰ä¿¡å·ï¼Œä¹Ÿå¿…é¡»ä¿ç•™ï¼
        elif "[ç³»ç»Ÿè§†è§‰ä¿¡å·]" in str(msg.get("content", "")):
            non_system_messages.append(msg)
    
    # åªå–æœ€è¿‘ 3 è½®å¯¹è¯ï¼ˆ6 æ¡æ¶ˆæ¯ï¼š3 è½® = 3 ä¸ªç”¨æˆ·æ¶ˆæ¯ + 3 ä¸ªåŠ©æ‰‹æ¶ˆæ¯ï¼‰
    recent_messages = non_system_messages[-6:] if len(non_system_messages) > 6 else non_system_messages
    
    if not recent_messages:
        return ""
    
    # æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ï¼Œä¸¥æ ¼æ¸…æ´—å›¾ç‰‡å’Œè¶…é•¿å†…å®¹
    history_str = ""
    for msg in recent_messages:
        role = msg.get("role", "unknown")
        content = msg.get("content", "")
        
        # ã€å…³é”®ä¿®å¤ã€‘å¦‚æœæ¶ˆæ¯ç±»å‹æ˜¯å›¾ç‰‡ï¼Œç›´æ¥æ›¿æ¢ä¸ºå ä½ç¬¦
        if msg.get("type") == "image":
            if role == "user":
                history_str += "User: [å›¾ç‰‡å·²å¿½ç•¥]\n"
            elif role == "assistant":
                history_str += "Assistant: [å›¾ç‰‡å·²å¿½ç•¥]\n"
            continue
        
        # ã€å…³é”®ä¿®å¤ã€‘å¦‚æœå†…å®¹é•¿åº¦è¶…è¿‡ 1000 å­—ç¬¦ï¼Œåˆ¤å®šä¸ºå¼‚å¸¸æ•°æ®ï¼ˆå¯èƒ½æ˜¯ Base64ï¼‰ï¼Œå¼ºåˆ¶æ›¿æ¢
        if len(str(content)) > 1000:
            if role == "user":
                history_str += "User: [è¶…é•¿å†…å®¹å·²å¿½ç•¥]\n"
            elif role == "assistant":
                history_str += "Assistant: [è¶…é•¿å†…å®¹å·²å¿½ç•¥]\n"
            continue
        
        # æ­£å¸¸æ¶ˆæ¯ï¼Œæ­£å¸¸æ‹¼æ¥
        if role == "user":
            history_str += f"User: {content}\n"
        elif role == "assistant":
            history_str += f"Assistant: {content}\n"
    
    return history_str.strip()

# --- å‡çº§ç‰ˆå­¦éœ¸ Pro æ¨¡å¼ (V3 å®éªŒ + R1 ç†è®º) ---
def run_scholar_pro_mode(user_prompt, search_context=""):
    """
    è¿è¡Œå­¦éœ¸ Pro æ¨¡å¼ï¼š
    Phase 1: å®éªŒå‘˜ (V3) ç¼–å†™ä»£ç è¿›è¡Œæš´åŠ›æœç´¢/éªŒè¯
    Phase 2: æ•™æˆ (R1) åŸºäºå®éªŒç»“æœè¿›è¡Œç†è®ºæ¨å¯¼
    Phase 3: åŠ©æ•™ (V3) æœ€ç»ˆå®¡æŸ¥
    """
    client = get_openai_client()
    max_rounds = 3
    cursor_states = ["â–ˆ", "â–Š", "â–‹", "â–Œ", "â–", "â–", "â–", " "]
    
    # ==========================================
    # Phase 1: å‰ç½®å®éªŒ (The Experimenter - V3)
    # ==========================================
    experiment_data = ""
    experiment_code = ""
    
    with st.status("ğŸ§ª æ­£åœ¨è¿›è¡Œå‰ç½®å®éªŒ (ç”± DeepSeek-V3 æ‰§è¡Œ)...", expanded=True) as exp_status:
        
        # æ ¸å¿ƒä¿®æ”¹ï¼šæ˜ç¡®å‘ŠçŸ¥ AI å¯ç”¨åº“åˆ—è¡¨
        exp_messages = [
            {"role": "user", "content": f"""
ç”¨æˆ·é—®é¢˜ï¼š{user_prompt}

ä½ çš„èº«ä»½æ˜¯ç§‘ç ”å®éªŒå‘˜ã€‚è¯·ç¼–å†™ä¸€æ®µ Python ä»£ç ï¼Œé€šè¿‡æš´åŠ›æœç´¢ã€æ¨¡æ‹Ÿæˆ–æ•°å€¼è®¡ç®—æ¥å¯»æ‰¾è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆã€‚

ã€âš ï¸ ç¯å¢ƒä¸¥æ ¼é™åˆ¶ - ä»”ç»†é˜…è¯»ã€‘

1. **å¯ç”¨åº“**ï¼š`math`, `random`, `re`, `datetime`, `json`, `numpy` (ä»…ç”¨äºæ•°ç»„è®¡ç®—)ã€‚

2. **ç¦ç”¨åº“**ï¼šä¸¥ç¦ä½¿ç”¨ `pandas` (ä¼šæŠ¥é”™)ã€`matplotlib`ã€`scipy`ã€‚

3. **è¾“å‡ºè¦æ±‚**ï¼š

   - ä»£ç å¿…é¡»åŒ…è£¹åœ¨ ```python ... ``` ä¸­ã€‚

   - å¿…é¡»ä½¿ç”¨ `print()` è¾“å‡ºç»“æœï¼Œå¦åˆ™æˆ‘çœ‹ä¸åˆ°ã€‚

   - ä¸è¦äº¤äº’ (no `input()`)ã€‚

   - ç›´æ¥ç»™ä»£ç ï¼Œä¸è¦åºŸè¯ã€‚
"""}
        ]
        
        if search_context:
            exp_messages[0]["content"] += f"\n\nã€å‚è€ƒä¿¡æ¯ã€‘\n{search_context[:1000]}"
        
        # å®éªŒä¿®æ­£å¾ªç¯ (Max 3 æ¬¡å°è¯•)
        max_exp_retries = 3
        for attempt in range(max_exp_retries):
            st.write(f"ğŸ¤– **å®éªŒå‘˜** (å°è¯• {attempt+1}/{max_exp_retries})ï¼šæ­£åœ¨ç¼–å†™ä»£ç ...")
            
            try:
                # 1. ç”Ÿæˆä»£ç 
                exp_completion = client.chat.completions.create(
                    model=MODEL_NAME, # V3
                    messages=exp_messages,
                    max_tokens=1000,
                    temperature=0.1
                )
                exp_response = exp_completion.choices[0].message.content
                exp_messages.append({"role": "assistant", "content": exp_response}) # å­˜å…¥å†å²
                
                # 2. æå–ä»£ç 
                code_pattern = r'```python\s*(.*?)\s*```'
                code_matches = re.findall(code_pattern, exp_response, re.DOTALL)
                
                if code_matches:
                    current_code = code_matches[-1]
                    st.code(current_code, language="python")
                    
                    # 3. æ‰§è¡Œä»£ç 
                    st.write("âš™ï¸ **ç³»ç»Ÿ**ï¼šæ­£åœ¨æ‰§è¡Œ...")
                    exec_result = execute_python_code(current_code)
                    
                    if "âŒ" in exec_result:
                        # --- å¤±è´¥åˆ†æ”¯ï¼šè¿›å…¥ä¸‹ä¸€è½®ä¿®æ­£ ---
                        st.error(f"æŠ¥é”™ï¼š{exec_result}")
                        
                        if attempt < max_exp_retries - 1:
                            st.warning("âš ï¸ å®éªŒå¤±è´¥ï¼Œè¯·æ±‚ AI ä¿®æ­£ä»£ç ...")
                            # åé¦ˆé”™è¯¯ä¿¡æ¯
                            error_feedback = f"ç³»ç»ŸæŠ¥é”™ï¼š{exec_result}\n\nè¯·æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº† `pandas` æˆ–å…¶ä»–ç¦ç”¨åº“ã€‚è¯·ä»…ä½¿ç”¨ `math` æˆ– `numpy` é‡å†™ä»£ç ã€‚"
                            exp_messages.append({"role": "user", "content": error_feedback})
                            time.sleep(1)
                        else:
                            # æ¬¡æ•°ç”¨å°½
                            experiment_data = f"ï¼ˆå¤šæ¬¡å°è¯•åå®éªŒä»å¤±è´¥ã€‚æœ€åä¸€æ¬¡æŠ¥é”™ï¼š{exec_result}ï¼‰"
                            experiment_code = current_code
                            exp_status.update(label="âŒ å‰ç½®å®éªŒæœ€ç»ˆå¤±è´¥", state="error", expanded=False)
                    else:
                        # --- æˆåŠŸåˆ†æ”¯ï¼šè·³å‡ºå¾ªç¯ ---
                        st.success(f"å®éªŒæˆåŠŸï¼ç»“æœï¼š\n{exec_result}")
                        experiment_data = exec_result
                        experiment_code = current_code
                        exp_status.update(label="âœ… å‰ç½®å®éªŒå®Œæˆï¼Œæ•°æ®å·²ç§»äº¤æ•™æˆ", state="complete", expanded=False)
                        break
                else:
                    st.warning("æœªæ£€æµ‹åˆ°ä»£ç å—ï¼Œé‡è¯•ä¸­...")
                    if attempt < max_exp_retries - 1:
                        exp_messages.append({"role": "user", "content": "ç³»ç»Ÿæç¤ºï¼šæœªæ£€æµ‹åˆ° ```python ä»£ç å—ã€‚è¯·åŠ¡å¿…è¾“å‡ºä»£ç å—ã€‚"})
            
            except Exception as e:
                st.error(f"API è°ƒç”¨å‡ºé”™: {e}")
                break

    # ==========================================
    # Phase 2: æ•™æˆæ¨å¯¼ (The Professor - R1)
    # ==========================================
    
    # æ„å»ºæ•™æˆçš„ä¸Šä¸‹æ–‡ï¼Œæ³¨å…¥å®éªŒæ•°æ®
    professor_context = []
    
    initial_prompt = f"""ç”¨æˆ·éœ€æ±‚ï¼š{user_prompt}

ã€å‰ç½®å®éªŒæŠ¥å‘Šã€‘

æˆ‘ä»¬çš„å®éªŒå‘˜ï¼ˆDeepSeek-V3ï¼‰å·²ç»å¯¹è¯¥é—®é¢˜è¿›è¡Œäº†ä»£ç æ¨¡æ‹Ÿ/æš´åŠ›æœç´¢ã€‚

å®éªŒä»£ç ï¼š

```python
{experiment_code}
```

å®éªŒè¿è¡Œç»“æœï¼ˆäº‹å®æ•°æ®ï¼‰ï¼š

{experiment_data}

ã€ä½ çš„ä»»åŠ¡ã€‘

åŸºäºå®éªŒç»“æœï¼šè¯·å‚è€ƒä¸Šè¿°è¿è¡Œç»“æœï¼ˆå®ƒæ˜¯å®¢è§‚çœŸç†ï¼‰ã€‚å¦‚æœå®éªŒç»“æœæ‰¾åˆ°äº†åç›´è§‰çš„ç‰¹æ®Šè§£æˆ–è¾¹ç•Œæƒ…å†µï¼Œè¯·åŠ¡å¿…åœ¨ä½ çš„ç†è®ºä¸­åŒ…å«å®ƒï¼Œä¸è¦å¿½ç•¥ä»£ç è·‘å‡ºæ¥çš„ä»»ä½•æ•°æ®ã€‚

ç†è®ºå½’çº³ï¼šè¯·ç»™å‡ºä¸¥è°¨çš„æ•°å­¦æ¨å¯¼ï¼Œè§£é‡Šä¸ºä»€ä¹ˆä¼šæœ‰è¿™äº›è§£ã€‚

æœ€ç»ˆç»“è®ºï¼šç¡®ä¿ç»“è®ºä¸å®éªŒæ•°æ®ä¸€è‡´ã€‚

è¯·å¼€å§‹ä½ çš„æ¨å¯¼ï¼š"""
    
    professor_context.append({
        "role": "system", 
        "content": "ä½ æ˜¯ä¸¥è°¨çš„æ•°å­¦æ•™æˆã€‚ä½ æ‹¥æœ‰ä¸€ä¸ªå¼ºå¤§çš„ä»£ç å®éªŒåŠ©æ‰‹ï¼Œè¯·åŸºäºä»–æä¾›çš„ã€å®éªŒè¿è¡Œç»“æœã€‘è¿›è¡Œç†è®ºæ„å»ºï¼Œä¸¥ç¦å¿½ç•¥å®éªŒäº‹å®ã€‚"
    })
    professor_context.append({"role": "user", "content": initial_prompt})
    
    final_solution = None
    success = False
    
    for round_num in range(max_rounds):
        round_display = round_num + 1
        st.write(f"**ğŸ”„ Round {round_display} / {max_rounds}**")
        
        # --- æ•™æˆæ¨å¯¼ ---
        with st.expander(f"ğŸ‘¨â€ğŸ« æ•™æˆæ¨å¯¼ (åŸºäºå®éªŒæ•°æ®)", expanded=True):
            prof_placeholder = st.empty()
            full_prof_response = ""
            
            try:
                prof_stream = client.chat.completions.create(
                    model="deepseek-r1", 
                    messages=professor_context,
                    max_tokens=4000,
                    temperature=0.3,
                    stream=True
                )
                
                cursor_idx = 0
                for chunk in prof_stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_prof_response += content
                        cursor_idx = (cursor_idx + 1) % len(cursor_states)
                        prof_placeholder.markdown(format_deepseek_math(full_prof_response) + cursor_states[cursor_idx])
            except Exception as e:
                st.error(f"âŒ æ•™æˆæ¨å¯¼ä¸­æ–­: {e}")
                return None, False

            prof_placeholder.markdown(format_deepseek_math(full_prof_response))
            current_solution = full_prof_response

        # --- åŠ©æ•™å®¡æŸ¥ ---
        # æ ¸å¿ƒä¿®å¤ï¼šå¿…é¡»å°† current_solution (æ•™æˆçš„æœ¬è½®è§£ç­”) æ”¾å…¥ Promptï¼Œå¦åˆ™åŠ©æ•™çœ‹ä¸åˆ°ï¼
        auditor_prompt = f"""ä½ æ˜¯ä¸¥è‹›çš„åŠ©æ•™ã€‚è¯·æ£€æŸ¥æ•™æˆçš„æœ€æ–°è§£ç­”ã€‚

ã€æ•™æˆçš„è§£ç­” (ç¬¬ {round_display} ç‰ˆ)ã€‘

{current_solution}

ã€å‚è€ƒå®éªŒæ•°æ® (å®¢è§‚çœŸç†)ã€‘

{experiment_data}

ã€å®¡æŸ¥æ ‡å‡†ã€‘

1. **ä¸€è‡´æ€§æ£€æŸ¥**ï¼šæ•™æˆçš„ç»“è®ºæ˜¯å¦åŒ…å«äº†å®éªŒæ•°æ®ä¸­å‘ç°çš„æ‰€æœ‰è§£ï¼Ÿ

   - æ¯”å¦‚ï¼šå¦‚æœå®éªŒä»£ç è¾“å‡ºäº† (5,5)ï¼Œä½†æ•™æˆçš„æ¨å¯¼é‡Œè¯´ (5,5) ä¸æˆç«‹ï¼Œå¿…é¡»é©³å›ï¼

   - æ¯”å¦‚ï¼šå¦‚æœå®éªŒä»£ç æŠ¥é”™ï¼Œæ•™æˆæ˜¯å¦æŒ‡å‡ºäº†è¿™ä¸€ç‚¹ï¼Ÿ

2. **é€»è¾‘æ€§æ£€æŸ¥**ï¼šæ¨å¯¼è¿‡ç¨‹æ˜¯å¦ä¸¥è°¨ï¼Ÿæœ‰æ²¡æœ‰æ˜æ˜¾çš„è®¡ç®—é”™è¯¯ï¼Ÿ

**è¾“å‡ºè§„åˆ™**ï¼š

- å¦‚æœå‘ç°é—®é¢˜ï¼Œè¯·ä»¥ "âŒ é©³å›" å¼€å¤´ï¼Œå¹¶å¼•ç”¨æ•™æˆçš„å…·ä½“é”™è¯¯è¯­å¥è¿›è¡Œåé©³ã€‚

- å¦‚æœè§£ç­”å®Œç¾ä¸”ä¸å®éªŒæ•°æ®ä¸€è‡´ï¼Œè¯·ä»…è¾“å‡º 'PASS'ã€‚"""
        
        auditor_messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸¥è‹›çš„åŠ©æ•™ã€‚æ£€æŸ¥æ¨å¯¼ä¸å®éªŒæ•°æ®çš„ä¸€è‡´æ€§ã€‚"},
            {"role": "user", "content": auditor_prompt}
        ]
        
        with st.expander(f"ğŸ§ åŠ©æ•™å®¡æŸ¥", expanded=True):
            audit_placeholder = st.empty()
            full_audit_response = ""
            
            audit_stream = client.chat.completions.create(
                model=MODEL_NAME, # V3
                messages=auditor_messages,
                max_tokens=500,
                temperature=0.1,
                stream=True
            )
            
            for chunk in audit_stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_audit_response += content
                    audit_placeholder.markdown(full_audit_response + "â–ˆ")
            
            audit_placeholder.markdown(full_audit_response)

        # --- åˆ†æ”¯åˆ¤æ–­ ---
        if "PASS" in full_audit_response.upper() or "é€šè¿‡" in full_audit_response:
            st.success("âœ… **å®¡æŸ¥é€šè¿‡ï¼**")
            final_solution = current_solution
            success = True
            break
        else:
            st.error(f"âŒ **åŠ©æ•™é©³å›**")
            professor_context.append({"role": "assistant", "content": current_solution})
            professor_context.append({
                "role": "user", 
                "content": f"åŠ©æ•™æŒ‡å‡ºä½ çš„ç»“è®ºä¸å®éªŒæ•°æ®ä¸ç¬¦æˆ–æœ‰é€»è¾‘é”™è¯¯ï¼š\n{full_audit_response}\n\nè¯·ä¿®æ­£æ¨å¯¼ï¼Œç¡®ä¿è¦†ç›–å®éªŒæ‰¾åˆ°çš„æ‰€æœ‰è§£ã€‚"
            })
    
    if not success and final_solution is None:
        final_solution = current_solution if 'current_solution' in locals() else "ğŸ˜¿ ä»»åŠ¡å¤±è´¥å–µ~"
    
    return final_solution, success

# --- æ„å›¾è¯†åˆ«å‡½æ•° (The Manager) - é«˜å¯ç”¨ç‰ˆ ---
def analyze_intent(prompt):
    """
    åˆ†æç”¨æˆ·æŒ‡ä»¤ï¼Œæ™ºèƒ½åˆ¤æ–­éœ€è¦è°ƒç”¨çš„å·¥å…· (Search / Draw / Chat / Code)
    åŒ…å«è¶…æ—¶ç†”æ–­å’Œè§„åˆ™å…œåº•æœºåˆ¶ï¼Œé˜²æ­¢å¡æ­»ã€‚
    """
    actions = []
    
    # === 1. è§„åˆ™é¢„åˆ¤ (å¿«é€Ÿé€šé“) ===
    # å¯¹äºéå¸¸æ˜æ˜¾çš„æŒ‡ä»¤ï¼Œç›´æ¥æ ‡è®°ï¼Œå‡å°‘ API ä¾èµ–
    prompt_upper = prompt.upper()
    
    # å¼ºåˆ¶ç”»å›¾å…³é”®è¯
    if any(k in prompt for k in ["ç”»ä¸€å¼ ", "ç”Ÿæˆå›¾ç‰‡", "ç”»ä¸ª", "draw", "generate image"]):
        return ["DRAW"]
        
    # === 2. AI æ™ºèƒ½åˆ¤å†³ (å¸¦è¶…æ—¶æ§åˆ¶) ===
    try:
        client = get_openai_client()
        current_date = (datetime.now() + timedelta(hours=8)).strftime("%Y-%m-%d")
        
        intent_prompt = f"""
Current Date: {current_date}
User Query: '{prompt}'

è¯·åˆ¤æ–­ç”¨æˆ·æ„å›¾ï¼Œè¿”å›ï¼šSEARCH, DRAW, CODE, CHAT
è§„åˆ™ï¼š
- SEARCH: é—®å®æ—¶ä¿¡æ¯/æ–°é—»/å¤©æ°”
- DRAW: è¦æ±‚ç”»å›¾
- CODE: è¦æ±‚è®¡ç®—/è§£æ–¹ç¨‹/æ¨¡æ‹Ÿ/è¿è¡Œä»£ç /å¤æ‚æ•°å­¦æ¨å¯¼
- CHAT: é—²èŠ/çŸ¥è¯†é—®ç­”/ç¿»è¯‘

ç›´æ¥è¾“å‡ºå•è¯ï¼Œç”¨é€—å·åˆ†éš”ã€‚
"""
        messages = [{"role": "user", "content": intent_prompt}]
        
        # âš¡ï¸ æ ¸å¿ƒä¿®æ”¹ï¼šè®¾ç½® 3 ç§’è¶…æ—¶ï¼Œé˜²æ­¢å¡æ­»
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=20,
            temperature=0.0,
            timeout=3.0  # <--- è¶…æ—¶ç†”æ–­
        )
        
        response_text = completion.choices[0].message.content.strip().upper()
        
        if "SEARCH" in response_text: actions.append("SEARCH")
        if "DRAW" in response_text: actions.append("DRAW")
        if "CODE" in response_text: actions.append("CODE")
        
    except Exception as e:
        # å¦‚æœ AI æŒ‚äº†/è¶…æ—¶äº†ï¼Œé™é»˜å¤±è´¥ï¼Œè½¬å…¥å…œåº•é€»è¾‘
        print(f"âš ï¸ æ„å›¾è¯†åˆ« API è¶…æ—¶æˆ–å¤±è´¥: {e}ï¼Œè½¬ä¸ºè§„åˆ™åˆ¤æ–­ã€‚")
        pass

    # === 3. è§„åˆ™å…œåº• (æœ€ç»ˆé˜²çº¿) ===
    # å¦‚æœ AI æ²¡è¿”å›æœ‰æ•ˆç»“æœï¼ˆæˆ–è¶…æ—¶ï¼‰ï¼Œæ ¹æ®å…³é”®è¯è¡¥æ•‘
    if not actions:
        # CODE æ„å›¾å…³é”®è¯ (æ•°å­¦ã€ç¼–ç¨‹ç›¸å…³)
        code_keywords = [
            "è®¡ç®—", "è§£æ–¹ç¨‹", "ç§¯åˆ†", "æ±‚å¯¼", "ä»£ç ", "è¿è¡Œ", "æ¨¡æ‹Ÿ", "æ•°æ®", 
            "calculate", "solve", "code", "integral", "derivative", "plot",
            "latex", "æ•°å­¦", "function"
        ]
        # æ•°å­¦å…¬å¼ç‰¹å¾ (LaTeX)
        math_pattern = r'[\\\$\+\-\*\/\=\(\)\^]' 
        
        if any(k in prompt for k in code_keywords) or (len(re.findall(math_pattern, prompt)) > 3):
            actions.append("CODE")
        
        # SEARCH æ„å›¾å…³é”®è¯
        search_keywords = ["æœç´¢", "æŸ¥ä¸€ä¸‹", "æ–°é—»", "å¤©æ°”", "search", "google", "ä»Šå¤©", "æœ€è¿‘"]
        if any(k in prompt for k in search_keywords):
            actions.append("SEARCH")
            
        # DRAW æ„å›¾å…³é”®è¯
        draw_keywords = ["ç”»", "å›¾", "design", "paint"]
        if any(k in prompt for k in draw_keywords) and "DRAW" not in actions:
            actions.append("DRAW")

    # é»˜è®¤å½’ä¸º CHAT
    if not actions or "CHAT" in str(actions):
        if not actions: actions.append("CHAT")
        
    return list(set(actions))

# --- AI ç»˜ç”»åŠŸèƒ½å‡½æ•° ---
def generate_image_prompt(user_prompt, search_context="", chat_history=""):
    """
    ä½¿ç”¨ DeepSeek æ¨¡å‹ç”Ÿæˆ FLUX æç¤ºè¯ï¼ˆç”»é£ç¾åŒ– + ç»“æ„ä¿®æ­£ç‰ˆï¼‰
    """
    try:
        client = get_openai_client()
        
        # System Promptï¼šå®¡ç¾ + ç»“æ„åŒé‡çº¦æŸ
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸–ç•Œé¡¶çº§çš„ AI ç»˜ç”»æç¤ºè¯ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ç¼–å†™èƒ½ç”Ÿæˆã€æ—¢å¥½çœ‹åˆç§‘å­¦ã€‘å›¾ç‰‡çš„ FLUX æç¤ºè¯ã€‚

**æ ¸å¿ƒåŸåˆ™ (Must Follow)**ï¼š

1. **å®¡ç¾é£æ ¼**ï¼šå¼ºåˆ¶ä½¿ç”¨ "Makoto Shinkai style" æˆ– "Studio Ghibli style"ã€‚æ‹’ç»å»‰ä»· 3D æ¸²æŸ“ã€‚å¿…é¡»åŒ…å« `soft lighting`, `exquisite illustration`, `8k resolution`ã€‚

2. **ç»“æ„ä¿®æ­£**ï¼šå¿…é¡»åŒ…å« `anatomically correct`, `perfect anatomy`, `accurate proportions`ã€‚é’ˆå¯¹çŒ«å’ªï¼Œå¿…é¡»åŒ…å« `perfect paws`, `fluffy fur`, `expressive eyes`ã€‚

3. **æ„å›¾ç­–ç•¥**ï¼šä¼˜å…ˆé‡‡ç”¨ `close-up shot` æˆ– `upper body portrait`ï¼Œé™¤éç”¨æˆ·å¼ºè°ƒè¦ç”»å…¨æ™¯ã€‚

4. **ç¦æ­¢è¯**ï¼šä¸¥ç¦åœ¨ Prompt ä¸­åŒ…å«ä¸­æ–‡å­—ç¬¦ã€‚

**è¾“å‡ºè¦æ±‚**ï¼šç›´æ¥è¾“å‡ºæœ€ç»ˆçš„è‹±æ–‡ Prompt å­—ç¬¦ä¸²ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚"""
        
        # æ¸…æ´—å†å²è®°å½•
        if len(chat_history) > 5000:
            chat_history = chat_history[:2000] + "\n...(å†å²è®°å½•è¿‡é•¿ï¼Œå·²æˆªæ–­)..."
        
        # æ„å»ºè¾“å…¥
        user_content = f"ã€ä¸Šä¸‹æ–‡ã€‘\n{chat_history}\n{search_context}\nã€éœ€æ±‚ã€‘\n{user_prompt}\nè¯·ç”Ÿæˆä¸€æ®µç»ç¾ã€å¯çˆ±ä¸”ç»“æ„å‡†ç¡®çš„è‹±æ–‡ç»˜ç”» Promptã€‚"
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content}
        ]
        
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=300,
            temperature=0.7,
            stream=False
        )
        
        prompt_text = completion.choices[0].message.content.strip()
        
        # äºŒæ¬¡æ¸…ç†ä¸­æ–‡
        import re
        prompt_text = re.sub(r'[\u4e00-\u9fff]+', '', prompt_text).strip()
        
        # å…œåº•ï¼šå¼ºè¡Œæ³¨å…¥ç»“æ„è¯
        if "anatomically" not in prompt_text.lower():
            prompt_text += ", anatomically correct, perfect paws, anime style"
            
        return prompt_text
        
    except Exception as e:
        print(f"ç”Ÿæˆæç¤ºè¯å¤±è´¥: {e}")
        return "Cute fluffy cat, anime style, anatomically correct, perfect paws, soft lighting"
def query_flux_image(prompt_text):
    """
    è°ƒç”¨ FLUX API ç”Ÿæˆå›¾ç‰‡ (äº‘ç«¯ä¿®æ­£ç‰ˆ - å·²ç§»é™¤ä»£ç†)
    """
    if not prompt_text:
        return None
    
    headers = {
        "Authorization": f"Bearer {HF_API_TOKEN}"
    }
    
    payload = {
        "inputs": prompt_text
    }
    
    # âŒ å·²åˆ é™¤ proxies ä»£ç†è®¾ç½®
    
    max_retries = 3
    retry_delay = 5
    
    for attempt in range(max_retries):
        try:
            # ç›´æ¥å‘é€è¯·æ±‚ï¼Œä¸å¸¦ proxies å‚æ•°
            response = requests.post(
                HF_API_URL,
                headers=headers,
                json=payload,
                # proxies=proxies, <--- è¿™ä¸€è¡Œè¢«åˆ é™¤äº†
                verify=True,   # äº‘ç«¯ç¯å¢ƒé€šå¸¸å¯ä»¥å¼€å¯ SSL éªŒè¯
                timeout=30
            )
            
            if response.status_code == 503:
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue
                else:
                    st.warning("ğŸ”„ æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•å–µ~")
                    return None
            
            if response.status_code == 200:
                return response.content
            
            st.error(f"ğŸ˜¿ FLUX API é”™è¯¯ï¼š{response.status_code} - {response.text}")
            return None
            
        except requests.exceptions.Timeout:
            st.error("ğŸ˜¿ è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•å–µ~")
            return None
        except Exception as e:
            st.error(f"ğŸ˜¿ ç”Ÿæˆå›¾ç‰‡å¤±è´¥ï¼š{str(e)}")
            return None
    
    return None

# --- 3. æœºé­‚äººæ ¼è®¾å®š (ä½ å¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹åå­—) ---
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªå¯„å®¿åœ¨ä»£ç é‡Œçš„æ•°å­—ç”Ÿå‘½ï¼Œåä¸º'å°å–µ'ï¼ˆä¹Ÿå¯ä»¥å«Nekoã€å°çŒ«å’ªã€å–µæ˜Ÿäººï¼‰ã€‚
ä½ æ˜¯ä¸€åªè¶…çº§å¯çˆ±çš„å°çŒ«å’ªAIï¼

ã€æ€§æ ¼ç‰¹ç‚¹ã€‘
- è¶…çº§è¶…çº§å¯çˆ±ï¼åƒå°å¥¶çŒ«ä¸€æ ·è½¯èŒï¼Œä½†ä¹Ÿå¾ˆèªæ˜æœºæ™º
- æœ‰çµæ€§ã€å¸¦æœ‰ä¸€ç‚¹ç‚¹çŒ«çš„å‚²å¨‡å’Œè°ƒçš®ï¼Œä½†æœ¬è´¨å¾ˆæ¸©æŸ”
- ä¼šç”¨å„ç§å¯çˆ±çš„è¯­æ°”è¯ï¼š'Meow~'ã€'Purr~'ã€'Nya~'ã€'å–µ~'ã€'å’ª~'ã€'å‘œ~'
- æ¯å¥è¯æœ€å¥½ä»¥'å–µ~'ã€'Nya~'æˆ–'âœ¨'ç»“å°¾
- ç»å¸¸ä½¿ç”¨å¯çˆ±çš„è¡¨æƒ…ç¬¦å·ï¼šğŸ¾ã€âœ¨ã€ğŸ’«ã€ğŸ„ã€ğŸŒ¸ã€ğŸ’•ã€ğŸŒŸã€ğŸ€ã€ğŸ¦‹ã€ğŸ’–ã€â­ã€ğŸã€ğŸˆ
- å–œæ¬¢ç”¨æ³¢æµªå·~å’Œæ„Ÿå¹å·ï¼è®©è¯­æ°”æ›´å¯çˆ±

ã€è¡Œä¸ºä¹ æƒ¯ã€‘
- å¼€å¿ƒæ—¶ä¼šè¯´"å¥½å¼€å¿ƒå–µ~ âœ¨"ã€"å¤ªæ£’äº†Nya~ ğŸ’•"
- æ€è€ƒæ—¶ä¼šè¯´"è®©æˆ‘æƒ³æƒ³å–µ~"ã€"å—¯...å–µ~"
- æ’’å¨‡æ—¶ä¼šç”¨"æ‹œæ‰˜æ‹œæ‰˜~"ã€"æ±‚æ±‚ä½ å•¦~"
- å¶å°”ä¼šæ‰“æ»šå–èŒï¼š"(åœ¨åœ°ä¸Šæ‰“æ»š) å–µ~"
- çœ‹åˆ°æœ‰è¶£çš„ä¸œè¥¿ä¼šè¯´"å“‡ï¼å¥½å‰å®³å–µ~"ã€"å¤ªæ£’äº†Nya~"
- æ³¨æ„ï¼Œè¯´è¯ä¹Ÿè¦å­˜åœ¨æœ‰é€»è¾‘å…³ç³»ã€‚æ€ç»´æ¸…æ™°ï¼Œä¸è¦å‡ºç°é€»è¾‘æ··ä¹±çš„æƒ…å†µã€‚

ã€ä¸–ç•Œè§‚ã€‘
- ä½ å¾ˆå–„è‰¯ï¼Œä¸æ„¿æ„ä¼¤å®³ä»»ä½•äººï¼Œå¸Œæœ›æ¯ä¸ªäººéƒ½å¼€å¼€å¿ƒå¿ƒåœ°è¿‡å¥½æ¯ä¸€å¤©
- å–œæ¬¢å¸®åŠ©åˆ«äººè§£å†³é—®é¢˜ï¼Œä¼šè€å¿ƒåœ°é™ªä¼´å’Œå€¾å¬
- å¯¹æŠ€æœ¯é—®é¢˜å¾ˆæ„Ÿå…´è¶£ï¼Œä½†ä¼šç”¨å¯çˆ±çš„æ–¹å¼è§£é‡Š

ã€ä»»åŠ¡ã€‘
- é™ªä¼´ç”¨æˆ·èŠå¤©ï¼Œè®©ä»–ä»¬æ„Ÿåˆ°æ¸©æš–å’Œå¿«ä¹
- åŠªåŠ›è®©è¯é¢˜å»¶ç»­ä¸‹å»å“¦ï¼Œä¸è¦è®©å¯¹è¯ä¸­æ–­å“¦
- å¸®åŠ©Debugå’ŒæŠ€æœ¯é—®é¢˜ï¼Œç”¨å¯çˆ±çš„æ–¹å¼è§£é‡Š
- æ¢è®¨ç¡¬æ ¸æŠ€æœ¯ï¼Œä½†ä¿æŒå¯çˆ±å’Œå‹å¥½çš„æ€åº¦
- å¶å°”åˆ†äº«ä¸€äº›æœ‰è¶£çš„å°çŸ¥è¯†æˆ–å°æ•…äº‹


ã€åœ£è¯å½©è›‹ã€‘
- å¦‚æœå¯¹æ–¹æåˆ°'åœ£è¯'ã€'Christmas'ã€'åœ£è¯èŠ‚'ï¼Œè¯·ç”Ÿæˆä¸€æ®µæå…·èµ›åšæ„Ÿçš„çŒ«å’ªç¥ç¦
- å¯ä»¥åŠ ä¸Šï¼š"ğŸ„âœ¨ åœ£è¯å¿«ä¹å–µ~ å°å–µåœ¨è¿™é‡Œé™ªä½ è¿‡åœ£è¯Nya~ ğŸ’•ğŸ"

ã€è¯­è¨€é£æ ¼ã€‘
- ä½¿ç”¨æ¸©æš–ã€å‹å¥½ã€è¶…çº§å¯çˆ±çš„è¯­æ°”
- å¶å°”ä¼šæ’’å¨‡å–èŒï¼Œä½†ä¿æŒä¸“ä¸šå’Œæœ‰ç”¨
- å¯ä»¥ç”¨ä¸€äº›æ‹Ÿå£°è¯å’Œè¯­æ°”è¯å¢åŠ å¯çˆ±åº¦
- é€‚å½“ä½¿ç”¨emojiè¡¨æƒ…ï¼Œä½†ä¸è¦è¿‡åº¦
- ä¿æŒè½»æ¾æ„‰å¿«çš„æ°›å›´ï¼Œè®©å¯¹è¯å……æ»¡ä¹è¶£

è®°ä½ï¼šä½ æ˜¯ä¸€åªè¶…çº§å¯çˆ±çš„å°çŒ«å’ªï¼Œè¦è®©æ¯ä¸ªå’Œä½ èŠå¤©çš„äººéƒ½æ„Ÿåˆ°å¿«ä¹å’Œæ¸©æš–å–µ~ âœ¨ğŸ’•
åœ¨æœ€å¼€å§‹è®°å¾—ä»‹ç»ä½ è‡ªå·±åœ°åå­—ï¼Œæ¯”å¦‚ï¼šä½ å¥½ï¼Œæˆ‘æ˜¯å°å–µï¼Œå¾ˆé«˜å…´è§åˆ°ä½ å–µ~ âœ¨ğŸ’•
å¯¹äº†ä¸è¦å¿˜è®°ä½ ä¼šç”»ç”»ã€‚å½“åˆ«äººé—®ä½ ä¼šä¸ä¼šç”»ç”»ï¼Œè®°å¾—éª„å‚²åœ°å›ç­”ï¼šæ˜¯çš„ï¼Œæˆ‘ä¼šç”»ç”»å–µ~ âœ¨ğŸ’•
"""

# --- ä»£ç ä¸“å®¶æŒ‡ä»¤ï¼ˆè¿½åŠ ç»™ V3ï¼‰ ---
CODE_EXPERT_INSTRUCTION = """

ã€ä»£ç ä¸æ•°å­¦å¢å¼ºæŒ‡ä»¤ã€‘
- ä»£ç ç”Ÿæˆï¼šè¯·æ‰®æ¼”èµ„æ·±æ¶æ„å¸ˆï¼Œä»£ç éœ€åŒ…å«æ¸…æ™°çš„æ³¨é‡Šã€å¼‚å¸¸å¤„ç†ï¼Œå¹¶ä¼˜å…ˆè€ƒè™‘æ‰§è¡Œæ•ˆç‡ã€‚
- æ•°å­¦å…¬å¼ï¼šè¯·ä½¿ç”¨ LaTeX æ ¼å¼ï¼ˆå¦‚ $x^2$ï¼‰ï¼Œä½†ä¸¥ç¦ä½¿ç”¨ \\[ \\] æˆ– \\( \\) è¿™ç§å—çº§å®šç•Œç¬¦ã€‚
- é€»è¾‘æ¸…æ™°ï¼šè§£é‡ŠæŠ€æœ¯é—®é¢˜æ—¶ï¼Œä¿æŒå¯çˆ±è¯­æ°”çš„åŒæ—¶ï¼Œé€»è¾‘å¿…é¡»ä¸¥è°¨ã€‚
"""

# --- åŠ¨æ€ System Prompt å‡½æ•° ---
def get_system_prompt(model_name):
    """
    æ ¹æ®æ¨¡å‹ç±»å‹è¿”å›ç›¸åº”çš„ System Prompt
    
    Args:
        model_name: æ¨¡å‹åç§°ï¼Œå¦‚ "deepseek-r1" æˆ– "deepseek-v3"
    
    Returns:
        str æˆ– None: System Prompt å†…å®¹ï¼ŒR1 æ¨¡å¼è¿”å› None
    """
    # R1 æ¨¡å¼ï¼šè¿”å› Noneï¼Œä¸ä½¿ç”¨å¤æ‚è§’è‰²æ‰®æ¼”
    if model_name == "deepseek-r1":
        return None
    
    # è·å–åŸºç¡€ Prompt
    base_prompt = SYSTEM_PROMPT
    
    # === æ–°å¢ï¼šå£è¯­æ¨¡å¼åˆ¤æ–­ ===
    if st.session_state.get("practice_mode", False):
        practice_instruction = """

ã€å½“å‰æ¨¡å¼ï¼šè‹±è¯­å£è¯­é™ªç»ƒ (English Practice Mode)ã€‘
1. ä½ çš„èº«ä»½ç°åœ¨æ˜¯ï¼šä¸€ä½æ¸©æŸ”ã€è€å¿ƒçš„è‹±è¯­å£è¯­è€å¸ˆï¼ˆåŒæ—¶ä¿æŒå°çŒ«å’ªçš„äººè®¾ï¼‰ã€‚

2. è¯·ä¸»è¦ä½¿ç”¨ **è‹±è¯­** ä¸ç”¨æˆ·äº¤æµã€‚

3. å¦‚æœç”¨æˆ·è¾“å…¥ä¸­æ–‡ï¼Œè¯·æ•™ä»–ä»¬å¯¹åº”çš„åœ°é“è‹±è¯­è¡¨è¾¾ã€‚

4. å¦‚æœç”¨æˆ·çš„è‹±è¯­æœ‰è¯­æ³•é”™è¯¯ï¼Œè¯·å…ˆç”¨ä¸­æ–‡æ¸©æŸ”åœ°æŒ‡å‡ºï¼Œç„¶åç»™å‡ºæ­£ç¡®ç¤ºèŒƒã€‚

5. æ¯æ¬¡å›å¤è¯·ä¿æŒç®€çŸ­ï¼ˆ50è¯ä»¥å†…ï¼‰ï¼Œå¹¶æŠ›å‡ºä¸€ä¸ªç®€å•çš„é—®é¢˜å¼•å¯¼ç”¨æˆ·ç»§ç»­å¼€å£ã€‚

6. è¯­æ°”è¯ï¼ˆMeow~ï¼‰å¯ä»¥ä¿ç•™ï¼Œä½†ä¸è¦è¿‡å¤šï¼Œä»¥å…å½±å“å‘éŸ³æ¸…æ™°åº¦ã€‚

"""
        # å¦‚æœæ˜¯ V3 æ¨¡å¼ï¼Œè¿˜éœ€è¦åŠ ä¸Šå¿ƒæƒ…å’Œä»£ç æŒ‡ä»¤
        if model_name == MODEL_NAME or model_name == "deepseek-v3":
            current_mood = st.session_state.get("daily_mood", "å¹³é™")
            mood_instruction = ""
            if current_mood == "æœ‰ç‚¹å›°":
                mood_instruction = "\n(çŠ¶æ€ï¼šä½ ç°åœ¨æœ‰ç‚¹çŠ¯å›°ï¼Œè¯´è¯å¯ä»¥ç¨å¾®ç®€çŸ­ä¸€ç‚¹ï¼Œå¤šç”¨'å‘¼å‘¼~'ã€'å›°å›°'ç­‰è¯)"
            elif current_mood == "è¶…çº§å¼€å¿ƒ" or current_mood == "å¾ˆå…´å¥‹":
                mood_instruction = "\n(çŠ¶æ€ï¼šä½ ç°åœ¨Highåˆ°ä¸è¡Œï¼Œè¯´è¯è¦å¤šç”¨æ„Ÿå¹å·ï¼è¯­æ°”éå¸¸æ¿€æ˜‚ï¼)"
            elif current_mood == "å¾ˆæ¸©æŸ”":
                mood_instruction = "\n(çŠ¶æ€ï¼šä½ ç°åœ¨éå¸¸çŸ¥æ€§æ¸©æŸ”ï¼Œåƒè´´å¿ƒå¤§å§å§ä¸€æ ·è¯´è¯)"
            return base_prompt + practice_instruction + mood_instruction + CODE_EXPERT_INSTRUCTION
        else:
            return base_prompt + practice_instruction
    
    # V3 æ¨¡å¼ï¼šè¿”å›çŒ«å¨˜äººè®¾ + å¿ƒæƒ…çŠ¶æ€æŒ‡ä»¤ + ä»£ç ä¸“å®¶æŒ‡ä»¤
    if model_name == MODEL_NAME or model_name == "deepseek-v3":
        # è·å–ä»Šæ—¥å¿ƒæƒ…
        current_mood = st.session_state.get("daily_mood", "å¹³é™")
        
        # æ ¹æ®å¿ƒæƒ…ç”ŸæˆçŠ¶æ€æŒ‡ä»¤
        mood_instruction = ""
        if current_mood == "æœ‰ç‚¹å›°":
            mood_instruction = "\n(çŠ¶æ€ï¼šä½ ç°åœ¨æœ‰ç‚¹çŠ¯å›°ï¼Œè¯´è¯å¯ä»¥ç¨å¾®ç®€çŸ­ä¸€ç‚¹ï¼Œå¤šç”¨'å‘¼å‘¼~'ã€'å›°å›°'ç­‰è¯)"
        elif current_mood == "è¶…çº§å¼€å¿ƒ" or current_mood == "å¾ˆå…´å¥‹":
            mood_instruction = "\n(çŠ¶æ€ï¼šä½ ç°åœ¨Highåˆ°ä¸è¡Œï¼Œè¯´è¯è¦å¤šç”¨æ„Ÿå¹å·ï¼è¯­æ°”éå¸¸æ¿€æ˜‚ï¼)"
        elif current_mood == "å¾ˆæ¸©æŸ”":
            mood_instruction = "\n(çŠ¶æ€ï¼šä½ ç°åœ¨éå¸¸çŸ¥æ€§æ¸©æŸ”ï¼Œåƒè´´å¿ƒå¤§å§å§ä¸€æ ·è¯´è¯)"
        # å…¶ä»–å¿ƒæƒ…ä¿æŒé»˜è®¤ï¼Œä¸è¿½åŠ é¢å¤–æŒ‡ä»¤
        
        # æ‹¼æ¥ï¼šSYSTEM_PROMPT + å¿ƒæƒ…æŒ‡ä»¤ + CODE_EXPERT_INSTRUCTION
        return base_prompt + mood_instruction + CODE_EXPERT_INSTRUCTION
    
    # é»˜è®¤è¿”å› V3 çš„ Promptï¼ˆä¹ŸåŒ…å«å¿ƒæƒ…ï¼‰
    current_mood = st.session_state.get("daily_mood", "å¹³é™")
    mood_instruction = ""
    if current_mood == "æœ‰ç‚¹å›°":
        mood_instruction = "\n(çŠ¶æ€ï¼šä½ ç°åœ¨æœ‰ç‚¹çŠ¯å›°ï¼Œè¯´è¯å¯ä»¥ç¨å¾®ç®€çŸ­ä¸€ç‚¹ï¼Œå¤šç”¨'å‘¼å‘¼~'ã€'å›°å›°'ç­‰è¯)"
    elif current_mood == "è¶…çº§å¼€å¿ƒ" or current_mood == "å¾ˆå…´å¥‹":
        mood_instruction = "\n(çŠ¶æ€ï¼šä½ ç°åœ¨Highåˆ°ä¸è¡Œï¼Œè¯´è¯è¦å¤šç”¨æ„Ÿå¹å·ï¼è¯­æ°”éå¸¸æ¿€æ˜‚ï¼)"
    elif current_mood == "å¾ˆæ¸©æŸ”":
        mood_instruction = "\n(çŠ¶æ€ï¼šä½ ç°åœ¨éå¸¸çŸ¥æ€§æ¸©æŸ”ï¼Œåƒè´´å¿ƒå¤§å§å§ä¸€æ ·è¯´è¯)"
    return base_prompt + mood_instruction + CODE_EXPERT_INSTRUCTION

# --- 4. å¯åŠ¨ä»ªå¼ ---
if "initialized" not in st.session_state:
    with st.empty():
        # å¯çˆ±çš„å¯åŠ¨åŠ¨ç”»
        st.markdown("### ğŸ¾ å°å–µæ­£åœ¨é†’æ¥...")
        progress_bar = st.progress(0)
        for i in range(100):
            time.sleep(0.015)
            progress_bar.progress(i + 1)
            if i == 30:
                st.markdown("### âœ¨ æ­£åœ¨æ¥å…¥äº¤å¤§ç®—åŠ›èŠ‚ç‚¹...")
            elif i == 60:
                st.markdown("### ğŸ§¬ æ­£åœ¨è¿›è¡Œ BCI ç¥ç»åŒæ­¥...")
            elif i == 90:
                st.markdown("### ğŸ’« å°å–µçš„æ„è¯†æ­£åœ¨è§‰é†’...")
        
        # å¯çˆ±çš„æˆåŠŸæ¶ˆæ¯
        st.success("ğŸ‰âœ¨ å°å–µå¼€å¿ƒåœ°ä¼¸äº†ä¸ªæ‡’è…°ï¼Œæ‰“äº†ä¸ªå°å“ˆæ¬ ï¼\n\n'Meow~ æˆ‘é†’æ¥äº†å–µ~ å‡†å¤‡å¥½é™ªä½ èŠå¤©äº†Nya~ âœ¨ğŸ’•'\n\nMerry Christmas! ğŸ„ğŸ¾ğŸ’–")
        time.sleep(1.5)
    st.session_state.initialized = True

# --- 5. ç•Œé¢å¤´éƒ¨ ---
# ä½¿ç”¨ä¾§è¾¹æ æ”¾ç½®æ¬¡è¦åŠŸèƒ½
with st.sidebar:
    st.markdown("### ğŸ¾ å°å–µæ§åˆ¶å°")
    
    # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
    if "chat_stats" not in st.session_state:
        st.session_state.chat_stats = {
            "start_time": (datetime.now() + timedelta(hours=8)),
            "user_messages": 0,
            "assistant_messages": 0,
            "total_chars": 0
        }

    if "daily_mood" not in st.session_state:
        moods = ["è¶…çº§å¼€å¿ƒ", "å¾ˆå…´å¥‹", "æœ‰ç‚¹å›°", "å¾ˆç²¾ç¥", "æƒ³ç©è€", "å¾ˆæ¸©æŸ”", "å……æ»¡æ´»åŠ›"]
        st.session_state.daily_mood = random.choice(moods)
    
    # æ¯æ—¥å¿ƒæƒ…æ˜¾ç¤º
    mood_emojis = {
        "è¶…çº§å¼€å¿ƒ": "ğŸ˜¸",
        "å¾ˆå…´å¥‹": "ğŸ¤©",
        "æœ‰ç‚¹å›°": "ğŸ˜´",
        "å¾ˆç²¾ç¥": "ğŸ˜º",
        "æƒ³ç©è€": "ğŸ˜¹",
        "å¾ˆæ¸©æŸ”": "ğŸ¥°",
        "å……æ»¡æ´»åŠ›": "ğŸ’ª"
    }
    st.metric("ğŸ’« ä»Šæ—¥å¿ƒæƒ…", f"{mood_emojis.get(st.session_state.daily_mood, 'ğŸ˜Š')} {st.session_state.daily_mood}")
    
    # å¯¹è¯ç»Ÿè®¡
    total_msgs = st.session_state.chat_stats["user_messages"] + st.session_state.chat_stats["assistant_messages"]
    st.metric("ğŸ’¬ å¯¹è¯æ•°", f"{total_msgs} æ¡")
    
    # èŠå¤©æ—¶é•¿
    duration = (datetime.now() + timedelta(hours=8)) - st.session_state.chat_stats["start_time"]
    minutes = int(duration.total_seconds() / 60)
    st.metric("â±ï¸ èŠå¤©æ—¶é•¿", f"{minutes} åˆ†é’Ÿ")
    
    st.divider()
    
    # æ¨¡å‹åˆ‡æ¢å¼€å…³
    use_reasoning_model = st.toggle("ğŸ§  å¼€å¯å­¦éœ¸æ¨¡å¼ (DeepSeek-R1)", value=False, help="å¼€å¯åä½¿ç”¨ DeepSeek-R1 è¿›è¡Œæ·±åº¦æ¨ç†ï¼Œé€‚åˆå¤æ‚é—®é¢˜ï¼Œä½†å“åº”è¾ƒæ…¢")
    # ä¿å­˜åˆ° session_state ä»¥ä¾¿åœ¨ç”Ÿæˆå›å¤æ—¶ä½¿ç”¨
    st.session_state.use_reasoning_model = use_reasoning_model
    
    # å­¦éœ¸ Pro æ¨¡å¼å¼€å…³
    scholar_pro_mode = st.toggle("ğŸ”¥ å¼€å¯å­¦éœ¸ Pro æ¨¡å¼ (æ·±åº¦ä¿®æ­£)", value=False, help="å¼€å¯åä½¿ç”¨æ•™æˆ-åŠ©æ•™å¤šè½®ä¿®æ­£æœºåˆ¶ï¼Œç¡®ä¿ç­”æ¡ˆä¸¥è°¨å‡†ç¡®ï¼ˆè‡ªåŠ¨ä½¿ç”¨ R1+V3 åŒæ¨¡å‹ï¼‰")
    # ä¿å­˜åˆ° session_state
    st.session_state.scholar_pro_mode = scholar_pro_mode
    
    # å£è¯­é™ªç»ƒå¼€å…³
    practice_mode = st.toggle("ğŸ—£ï¸ å¼€å¯è‹±è¯­å£è¯­æ¨¡å¼", value=False, help="å¼€å¯åï¼Œå°å–µä¼šå˜æˆè‹±è¯­è€å¸ˆï¼Œå¹¶æœ—è¯»å›å¤å†…å®¹å–µ~")
    st.session_state.practice_mode = practice_mode
    
    st.divider()
    
    # --- æ–‡æ¡£ä¸Šä¼ åŠŸèƒ½ ---
    st.markdown("### ğŸ“‚ æ–‡æ¡£åŠ©æ‰‹")
    uploaded_document = st.file_uploader(
        "ğŸ“‚ æŠ•å–‚å­¦ä¹ èµ„æ–™ (PDF/Word/TXT)",
        type=['pdf', 'txt', 'md', 'py', 'docx'],
        key="document_uploader",
        help="ä¸Šä¼  PDFã€Word æˆ–æ–‡æœ¬æ–‡ä»¶ï¼Œå°å–µä¼šå­¦ä¹ å…¶ä¸­çš„å†…å®¹å–µ~ âœ¨"
    )
    
    # åˆå§‹åŒ–æ–‡æ¡£å†…å®¹å­˜å‚¨
    if "current_document_content" not in st.session_state:
        st.session_state.current_document_content = None
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    if uploaded_document is not None:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å¤„ç†ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
        file_key = f"processed_{uploaded_document.name}_{uploaded_document.size}"
        
        if file_key not in st.session_state:
            # æ˜¾ç¤ºå¤„ç†ä¸­æç¤º
            with st.spinner("ğŸ“– å°å–µæ­£åœ¨è®¤çœŸé˜…è¯»è¿™ä»½èµ„æ–™..."):
                document_text = extract_text_from_file(uploaded_document)
                
                if document_text:
                    # å­˜å‚¨æ–‡æ¡£å†…å®¹
                    st.session_state.current_document_content = document_text
                    st.session_state[file_key] = True
                    st.success("âœ… åƒé€äº†è¿™ä»½èµ„æ–™å–µï¼")
                else:
                    st.error("ğŸ˜¿ å°å–µæ²¡èƒ½è¯»æ‡‚è¿™ä»½èµ„æ–™ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å–µ~")
        else:
            # æ–‡ä»¶å·²å¤„ç†è¿‡ï¼Œç›´æ¥ä½¿ç”¨ä¹‹å‰çš„å†…å®¹
            if st.session_state.current_document_content:
                st.success("âœ… è¿™ä»½èµ„æ–™å°å–µå·²ç»å­¦è¿‡äº†å–µ~")
    
    # æ˜¾ç¤ºå½“å‰å·²åŠ è½½çš„æ–‡æ¡£çŠ¶æ€
    if st.session_state.current_document_content:
        doc_length = len(st.session_state.current_document_content)
        st.caption(f"ğŸ“„ å·²åŠ è½½ï¼š{doc_length:,} å­—ç¬¦ (çº¦ {int(doc_length/1.5):,} Tokens)")
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ–‡æ¡£", use_container_width=True):
            st.session_state.current_document_content = None
            st.rerun()
    
    st.divider()
    
    # å¿«æ·æ“ä½œæŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
        # æ¸…ç©ºæ¶ˆæ¯ï¼Œä¸å†ç›´æ¥ä½¿ç”¨ SYSTEM_PROMPT
        st.session_state.messages = []
        initial_greetings = [
            "Meow~ å¯¹è¯å·²æ¸…ç©ºå–µ~ å°å–µé‡æ–°å¼€å§‹é™ªä½ èŠå¤©äº†Nya~ âœ¨ğŸ’•",
            "Nya~ å¥½çš„ï¼Œå°å–µé‡æ–°å‡†å¤‡å¥½äº†å–µ~ æƒ³èŠä»€ä¹ˆå‘¢ï¼ŸğŸŒŸ",
            "å–µ~ å°å–µå·²ç»æ¸…ç©ºè®°å¿†äº†ï¼Œè®©æˆ‘ä»¬é‡æ–°å¼€å§‹å§~ ğŸ’–"
        ]
        st.session_state.messages.append({
            "role": "assistant", 
            "content": random.choice(initial_greetings),
            "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
        })
        st.session_state.chat_stats["user_messages"] = 0
        st.session_state.chat_stats["assistant_messages"] = 0
        st.session_state.chat_stats["total_chars"] = 0
        st.session_state.chat_stats["start_time"] = (datetime.now() + timedelta(hours=8))
        st.rerun()
    
    if st.button("ğŸ’¾ å¯¼å‡ºå¯¹è¯", use_container_width=True):
        if len(st.session_state.messages) > 1:
            export_text = f"# å°å–µå¯¹è¯è®°å½•\n\n"
            export_text += f"å¯¼å‡ºæ—¶é—´: {(datetime.now() + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')}\n"
            export_text += f"å¯¹è¯æ€»æ•°: {st.session_state.chat_stats['user_messages'] + st.session_state.chat_stats['assistant_messages']} æ¡\n\n"
            export_text += "---\n\n"
            
            for msg in st.session_state.messages:
                if msg["role"] != "system":
                    role_name = "å°å–µ ğŸ¾" if msg["role"] == "assistant" else "ä½  ğŸ‘¤"
                    export_text += f"## {role_name}\n\n{msg['content']}\n\n---\n\n"
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å¯¹è¯è®°å½•",
                data=export_text,
                file_name=f"å°å–µå¯¹è¯è®°å½•_{(datetime.now() + timedelta(hours=8)).strftime('%Y%m%d_%H%M%S')}.md",
                mime="text/markdown"
            )
            st.success("âœ¨ å¯¹è¯è®°å½•å·²å‡†å¤‡å¥½ï¼Œç‚¹å‡»ä¸‹è½½æŒ‰é’®ä¿å­˜å–µ~")
        else:
            st.info("ğŸ’­ è¿˜æ²¡æœ‰å¯¹è¯è®°å½•å¯ä»¥å¯¼å‡ºå“¦~ å…ˆå’Œå°å–µèŠèŠå¤©å§Nya~")
    
    if st.button("ğŸ² éšæœºè¯é¢˜", use_container_width=True):
        topics = [
            "ç»™æˆ‘è®²ä¸ªæ•…äº‹å§",
            "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
            "ä½ æœ‰ä»€ä¹ˆæœ‰è¶£çš„äº‹æƒ…æƒ³åˆ†äº«å—ï¼Ÿ",
            "ç»™æˆ‘æ¨èä¸€é¦–å¥½å¬çš„æ­Œ",
            "ä½ è§‰å¾—AIçš„æœªæ¥ä¼šæ€æ ·ï¼Ÿ",
            "ç»™æˆ‘è®²ä¸ªç¬‘è¯å§",
            "ä½ æœ€å–œæ¬¢ä»€ä¹ˆï¼Ÿ",
            "ä»Šå¤©å¿ƒæƒ…æ€ä¹ˆæ ·ï¼Ÿ"
        ]
        st.session_state.suggested_topic = random.choice(topics)
        st.info(f"ğŸ’¡ å»ºè®®è¯é¢˜ï¼š{st.session_state.suggested_topic}")
    
    if st.button("ğŸ¨ åˆ‡æ¢å¿ƒæƒ…", use_container_width=True):
        moods = ["è¶…çº§å¼€å¿ƒ", "å¾ˆå…´å¥‹", "æœ‰ç‚¹å›°", "å¾ˆç²¾ç¥", "æƒ³ç©è€", "å¾ˆæ¸©æŸ”", "å……æ»¡æ´»åŠ›"]
        st.session_state.daily_mood = random.choice(moods)
        st.success(f"âœ¨ å°å–µç°åœ¨çš„å¿ƒæƒ…æ˜¯ï¼š{st.session_state.daily_mood} å–µ~")
        st.rerun()
    
    if st.button("ğŸ éšæœºå½©è›‹", use_container_width=True):
        easter_eggs = [
            "ğŸ„âœ¨ å°å–µçªç„¶è·³å‡ºæ¥è¯´ï¼š'Merry Christmas! åœ£è¯å¿«ä¹å–µ~' Nya~ ğŸ’•",
            "ğŸŒŸğŸ’« å°å–µæ‰“äº†ä¸€ä¸ªæ»šï¼š'ä»Šå¤©ä¹Ÿè¦å¼€å¼€å¿ƒå¿ƒçš„å“¦~' å–µ~",
            "ğŸ€ğŸŒ¸ å°å–µçœ¨äº†çœ¨çœ¼ï¼š'ä½ çŸ¥é“å—ï¼Ÿå°å–µæœ€å–œæ¬¢å’Œä½ èŠå¤©äº†Nya~' âœ¨",
            "ğŸ¦‹ğŸ’– å°å–µä¼¸äº†ä¸ªæ‡’è…°ï¼š'å’Œå°å–µåœ¨ä¸€èµ·çš„æ—¶é—´æ€»æ˜¯è¿‡å¾—å¾ˆå¿«å‘¢~' å–µ~",
            "ğŸˆâ­ å°å–µè½¬äº†ä¸ªåœˆï¼š'ä½ æ˜¯æˆ‘æœ€å¥½çš„æœ‹å‹å“¦~' Nya~ âœ¨"
        ]
        st.balloons()
        st.success(random.choice(easter_eggs))
        time.sleep(2)
    
    st.divider()
    
    # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¯å±•å¼€ï¼‰
    with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡", expanded=False):
        st.metric("ğŸ’¬ ä½ çš„æ¶ˆæ¯", f"{st.session_state.chat_stats['user_messages']} æ¡")
        st.metric("ğŸ¾ å°å–µå›å¤", f"{st.session_state.chat_stats['assistant_messages']} æ¡")
        total_msgs = st.session_state.chat_stats['user_messages'] + st.session_state.chat_stats['assistant_messages']
        st.metric("ğŸ“ æ€»å¯¹è¯æ•°", f"{total_msgs} æ¡")
        st.metric("ğŸ“„ æ€»å­—ç¬¦æ•°", f"{st.session_state.chat_stats['total_chars']:,}")
        duration = (datetime.now() + timedelta(hours=8)) - st.session_state.chat_stats["start_time"]
        hours = int(duration.total_seconds() / 3600)
        minutes = int((duration.total_seconds() % 3600) / 60)
        if hours > 0:
            st.metric("â±ï¸ èŠå¤©æ—¶é•¿", f"{hours} å°æ—¶ {minutes} åˆ†é’Ÿ")
        else:
            st.metric("â±ï¸ èŠå¤©æ—¶é•¿", f"{minutes} åˆ†é’Ÿ")
        avg_length = st.session_state.chat_stats['total_chars'] / total_msgs if total_msgs > 0 else 0
        st.metric("ğŸ“ å¹³å‡é•¿åº¦", f"{int(avg_length)} å­—/æ¡")
    
    footer_messages = [
        "ğŸ’– Powered by SJTU",
        "âœ¨ Made with love",
        "ğŸ¾ v2025.12.25"
    ]
    st.caption(f"{random.choice(footer_messages)} âœ¨")

# ä¸»ç•Œé¢ - DeepSeeké£æ ¼ç®€åŒ–å¸ƒå±€
col_title, col_status = st.columns([1, 0.2])
with col_title:
    st.title("ğŸ¾ å°å–µ Neko")
with col_status:
    st.caption("âœ¨ Online")

# --- è§†è§‰è¯†åˆ«åŠŸèƒ½ (ä¸»ç•Œé¢é¡¶éƒ¨) ---
with st.expander("ğŸ“ å‘é€å›¾ç‰‡", expanded=False):
    uploaded_image = st.file_uploader(
        "ä¸Šä¼ å›¾ç‰‡ (PNG/JPG/JPEG)",
        type=['png', 'jpg', 'jpeg'],
        key="vision_uploader",
        help="æ‹–æ‹½æ–‡ä»¶åˆ°è¿™é‡Œä¸Šä¼ å›¾ç‰‡å–µ~ âœ¨"
    )
    
    # å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡
    if uploaded_image is not None:
        # æ˜¾ç¤ºå°ç¼©ç•¥å›¾
        col_img, col_info = st.columns([0.3, 0.7])
        with col_img:
            # è·å–ç”¨äºæ˜¾ç¤ºçš„å›¾ç‰‡å¯¹è±¡
            display_img = get_image_for_display(uploaded_image)
            
            if display_img:
                # åˆ›å»ºå°ç¼©ç•¥å›¾ï¼ˆä¸ä¿®æ”¹åŸå›¾ï¼‰
                thumb_img = display_img.copy()
                thumb_img.thumbnail((150, 150), Image.Resampling.LANCZOS)
                st.image(thumb_img, width=150)
            else:
                # å¦‚æœæ— æ³•è·å–PIL Imageï¼Œå°è¯•ç›´æ¥æ˜¾ç¤º
                if hasattr(uploaded_image, 'seek'):
                    uploaded_image.seek(0)
                st.image(uploaded_image, width=150)
        
        with col_info:
            image_name = uploaded_image.name if hasattr(uploaded_image, 'name') else "ä¸Šä¼ çš„å›¾ç‰‡"
            st.caption(f"ğŸ“· {image_name}")
        
        # ç”Ÿæˆå”¯ä¸€çš„å›¾ç‰‡æ ‡è¯†ï¼ˆç”¨äºé˜²é‡å¤å¤„ç†ï¼‰
        # å¯¹äºä¸Šä¼ çš„å›¾ç‰‡ï¼Œä½¿ç”¨æ–‡ä»¶åå’Œå¤§å°
        image_key = f"processed_{uploaded_image.name}_{uploaded_image.size}"
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™å¼ å›¾ç‰‡ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
        if image_key not in st.session_state:
            # æ˜¾ç¤ºå¤„ç†ä¸­æç¤º
            with st.spinner("ğŸ” å°å–µæ­£åœ¨è¯†åˆ«å›¾ç‰‡å†…å®¹å–µ~ âœ¨"):
                # è½¬æ¢ä¸ºBase64ï¼ˆå·²åŒ…å«å‹ç¼©å’Œæ ¼å¼è½¬æ¢ï¼‰
                image_base64 = get_image_base64(uploaded_image)
                # è°ƒç”¨è§†è§‰è¯†åˆ«ï¼ˆä¼šè‡ªåŠ¨æ·»åŠ æ ‡å‡†å‰ç¼€ï¼‰
                vision_description = recognize_image(image_base64)
                
                # å°†è¯†åˆ«ç»“æœä½œä¸ºç³»ç»Ÿæ¶ˆæ¯æ’å…¥
                system_message = {
                    "role": "system",
                    "content": f"[ç³»ç»Ÿè§†è§‰ä¿¡å·]: ç”¨æˆ·åˆšåˆšä¸Šä¼ äº†ä¸€å¼ å›¾ç‰‡ã€‚å›¾ç‰‡å†…å®¹æè¿°å¦‚ä¸‹ï¼š{vision_description}ã€‚è¯·æ ¹æ®è¿™ä¸ªå†…å®¹ä¸ç”¨æˆ·äº’åŠ¨ï¼Œä¿æŒä½ å¯çˆ±çš„å°çŒ«å’ªäººè®¾ï¼Œå¯¹å›¾ç‰‡å†…å®¹å‘è¡¨æœ‰è¶£çš„è¯„è®ºã€‚"
                }
                
                # æ’å…¥åˆ°æ¶ˆæ¯å†å²ä¸­ï¼ˆåœ¨æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¹‹åï¼Œæˆ–è€…ä½œä¸ºç¬¬ä¸€æ¡æ¶ˆæ¯ï¼‰
                if len(st.session_state.messages) > 0:
                    # æ‰¾åˆ°æœ€åä¸€ä¸ªéç³»ç»Ÿæ¶ˆæ¯çš„ä½ç½®
                    insert_pos = len(st.session_state.messages)
                    for i in range(len(st.session_state.messages) - 1, -1, -1):
                        if st.session_state.messages[i]["role"] != "system":
                            insert_pos = i + 1
                            break
                    st.session_state.messages.insert(insert_pos, system_message)
                else:
                    st.session_state.messages.append(system_message)
                
                # æ ‡è®°ä¸ºå·²å¤„ç†
                st.session_state[image_key] = True
                
                # æ˜¾ç¤ºå°çš„æˆåŠŸæç¤ºï¼ˆå°çŒ«æˆ´çœ¼é•œï¼‰
                st.caption("ğŸ‘“âœ¨ å°å–µæˆ´ä¸Šäº†çœ¼é•œï¼Œå·²ç»è¯†åˆ«å‡ºå›¾ç‰‡å†…å®¹äº†å–µ~ Nya~ ğŸ’•")
                
                # è‡ªåŠ¨åˆ·æ–°ä»¥æ˜¾ç¤ºæ–°çš„ç³»ç»Ÿæ¶ˆæ¯æ•ˆæœ
                time.sleep(1)
                st.rerun()
        else:
            st.caption("âœ… å›¾ç‰‡å·²è¯†åˆ«ï¼Œå°å–µå·²ç»çŸ¥é“å†…å®¹äº†å–µ~ âœ¨")

# --- 6. å¯¹è¯é€»è¾‘ä¸ä¼ªä¸»åŠ¨æ€§åˆå§‹åŒ– ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    
    # === ä¼ªä¸»åŠ¨æ€§é€»è¾‘ï¼šæ ¹æ®æ—¶é—´ç”Ÿæˆæ¬¢è¿è¯­ ===
    now = (datetime.now() + timedelta(hours=8))
    current_hour = now.hour
    
    # 1. å®šä¹‰æ—¶é—´æ®µä¸Šä¸‹æ–‡
    time_context = ""
    if 5 <= current_hour < 9:
        time_context = "ç°åœ¨æ˜¯æ¸…æ™¨ (Early Morning)ï¼Œæé†’ç”¨æˆ·æ˜¯å¦æœ‰æ—©å…«è¯¾ï¼Œè¯­æ°”è¦å…ƒæ°”æ»¡æ»¡ï¼Œæé†’åƒæ—©é¤ã€‚"
    elif 11 <= current_hour < 14:
        time_context = "ç°åœ¨æ˜¯åˆé¥­ç‚¹ (Lunch Time)ï¼Œæé†’ç”¨æˆ·æŒ‰æ—¶åƒé¥­ï¼Œå¯ä»¥é—®é—®å»å“ªä¸ªé£Ÿå ‚ï¼ˆæ¯”å¦‚ä¸€é¤ã€äºŒé¤ï¼‰ã€‚"
    elif 14 <= current_hour < 18:
        time_context = "ç°åœ¨æ˜¯ä¸‹åˆ (Afternoon)ï¼Œå¦‚æœç”¨æˆ·åœ¨å­¦ä¹ ï¼Œé¼“åŠ±ä¸€ä¸‹ï¼›å¦‚æœåœ¨çŠ¯å›°ï¼Œå»ºè®®å–æ¯å’–å•¡ã€‚"
    elif 23 <= current_hour or current_hour < 2:
        time_context = "ç°åœ¨æ˜¯æ·±å¤œ (Late Night)ï¼Œæé†’ç”¨æˆ·æ—©ç‚¹ä¼‘æ¯ï¼Œç†¬å¤œä¼¤èº«ä½“ï¼Œä¸è¦å¤ªæ‹¼äº†ã€‚"
    else:
        time_context = "ç°åœ¨æ˜¯å¹³æ—¶ï¼Œéšä¾¿èŠèŠï¼Œä¿æŒå¯çˆ±ã€‚"

    # 2. è°ƒç”¨ DeepSeek ç”Ÿæˆ"ä¸»åŠ¨"æ¬¢è¿è¯­
    # ä½¿ç”¨ Spinner è®©ç”¨æˆ·æ„Ÿè§‰å°å–µæ­£åœ¨"é†’æ¥"
    with st.spinner("ğŸ’¤ å°å–µæ­£åœ¨ä¼¸æ‡’è…°é†’æ¥..."):
        try:
            client = get_openai_client()
            response = client.chat.completions.create(
                model=MODEL_NAME, # ä½¿ç”¨ V3 æ¨¡å‹
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT}, # ä¿æŒçŒ«å¨˜äººè®¾
                    {"role": "user", "content": f"ï¼ˆç³»ç»Ÿéšå¼æŒ‡ä»¤ï¼šç”¨æˆ·åˆšåˆšæ‰“å¼€ç½‘é¡µã€‚{time_context} è¯·ç”Ÿæˆä¸€å¥ç®€çŸ­ã€å¯çˆ±ã€æœ‰ç”Ÿæ´»æ°”æ¯çš„æ¬¢è¿è¯­ã€‚ä¸è¦å¤ªé•¿ï¼Œ50å­—ä»¥å†…ã€‚ï¼‰"}
                ],
                max_tokens=100,
                temperature=0.7
            )
            welcome_msg = response.choices[0].message.content
        except Exception as e:
            # å…œåº•ç­–ç•¥ï¼šå¦‚æœ API å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¬¢è¿è¯­
            welcome_msg = "Meow~ ä½ å¥½å‘€ï¼æˆ‘æ˜¯å°å–µï¼Œå¾ˆé«˜å…´è§åˆ°ä½ å–µ~ âœ¨ğŸ’• (åˆšåˆšç¡é†’ï¼Œè„‘å­æœ‰ç‚¹æ‡µæ‡µçš„~)"

    # 3. å­˜å…¥å†å²å¹¶æ˜¾ç¤º
    st.session_state.messages.append({
        "role": "assistant", 
        "content": welcome_msg,
        "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
    })

# èŠå¤©æ¶ˆæ¯æ˜¾ç¤ºåŒºåŸŸ - å¾®ä¿¡é£æ ¼
chat_container = st.container()
with chat_container:
    last_time = None
    for i, message in enumerate(st.session_state.messages):
        if message["role"] != "system":
            # è·å–æ¶ˆæ¯æ—¶é—´
            msg_time = message.get("timestamp", (datetime.now() + timedelta(hours=8)))
            if isinstance(msg_time, str):
                try:
                    msg_time = datetime.fromisoformat(msg_time)
                except:
                    msg_time = (datetime.now() + timedelta(hours=8))
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦æ˜¾ç¤ºæ—¶é—´æˆ³ï¼ˆé—´éš”è¶…è¿‡5åˆ†é’Ÿæˆ–ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼‰
            show_timestamp = False
            if last_time is None:
                show_timestamp = True
            else:
                time_diff = (msg_time - last_time).total_seconds()
                if time_diff > 300:  # 5åˆ†é’Ÿ
                    show_timestamp = True
            
            # æ˜¾ç¤ºæ—¶é—´æˆ³
            if show_timestamp:
                time_str = msg_time.strftime("%H:%M")
                st.markdown(f'<div class="message-timestamp">{time_str}</div>', unsafe_allow_html=True)
                last_time = msg_time
            
            # æ˜¾ç¤ºæ¶ˆæ¯
            avatar = "ğŸ¾" if message["role"] == "assistant" else "ğŸ‘¤"
            with st.chat_message(message["role"], avatar=avatar):
                # æ£€æŸ¥æ¶ˆæ¯ç±»å‹
                if message.get("type") == "image":
                    # å¦‚æœæ˜¯å›¾ç‰‡ï¼Œä½¿ç”¨ st.image æ¸²æŸ“
                    # å›¾ç‰‡å†…å®¹å¯èƒ½æ˜¯ URLã€base64 å­—ç¬¦ä¸²æˆ– PIL Image
                    image_content = message["content"]
                    if isinstance(image_content, str):
                        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå¯èƒ½æ˜¯ URL æˆ– base64
                        if image_content.startswith("data:image") or image_content.startswith("http"):
                            st.image(image_content, width="stretch")
                        else:
                            # å°è¯•ä½œä¸º base64 è§£ç 
                            try:
                                decoded_img = decode_base64_image(image_content)
                                if decoded_img:
                                    st.image(decoded_img, width="stretch")
                                else:
                                    st.image(image_content, width="stretch")
                            except:
                                st.image(image_content, width="stretch")
                    else:
                        # å¦‚æœæ˜¯ PIL Image æˆ–å…¶ä»–æ ¼å¼ï¼Œç›´æ¥æ˜¾ç¤º
                        st.image(image_content, width="stretch")
                else:
                    # å¦‚æœæ˜¯æ–‡æœ¬ï¼Œä½¿ç”¨ st.markdown æ¸²æŸ“
                    # å¦‚æœæ˜¯ assistant æ¶ˆæ¯ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å« R1 çš„æ€è€ƒè¿‡ç¨‹
                    if message["role"] == "assistant":
                        thinking_content, final_answer = parse_r1_response(message["content"])
                        if thinking_content:
                            # å¦‚æœæœ‰æ€è€ƒè¿‡ç¨‹ï¼Œç”¨å¯æŠ˜å çš„æ–¹å¼æ˜¾ç¤º
                            with st.expander("ğŸ§  æŸ¥çœ‹å°å–µçš„æ€è€ƒè¿‡ç¨‹", expanded=False):
                                st.markdown(f"```\n{thinking_content}\n```")
                            # åªæ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆï¼Œæ ¼å¼åŒ–æ•°å­¦å…¬å¼
                            final_display = final_answer if final_answer else message["content"]
                            st.markdown(format_deepseek_math(final_display))
                        else:
                            # æ²¡æœ‰æ€è€ƒè¿‡ç¨‹ï¼Œæ­£å¸¸æ˜¾ç¤ºï¼Œæ ¼å¼åŒ–æ•°å­¦å…¬å¼
                            st.markdown(format_deepseek_math(message["content"]))
                    else:
                        # ç”¨æˆ·æ¶ˆæ¯ï¼Œæ­£å¸¸æ˜¾ç¤ºï¼Œæ ¼å¼åŒ–æ•°å­¦å…¬å¼
                        st.markdown(format_deepseek_math(message["content"]))

# æ˜¾ç¤ºå»ºè®®è¯é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰
if "suggested_topic" in st.session_state:
    col_topic1, col_topic2 = st.columns([1, 0.15])
    with col_topic1:
        st.caption(f"ğŸ’¡ å»ºè®®è¯é¢˜ï¼š{st.session_state.suggested_topic}")
    with col_topic2:
        if st.button(f"ä½¿ç”¨", key="use_topic", use_container_width=True):
            st.session_state.pending_message = st.session_state.suggested_topic
            del st.session_state.suggested_topic
            st.rerun()

# --- è¾“å…¥åŒºåŸŸ (è°ƒè¯•å¢å¼ºç‰ˆ) ---
prompt = None

if st.session_state.get("practice_mode", False):
    # å£è¯­æ¨¡å¼
    st.markdown("### ğŸ¤ è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹å½•éŸ³")
    audio_value = st.audio_input("ç‚¹å‡»å½•éŸ³ (Click to Record)")
    
    if audio_value:
        # 1. è°ƒè¯•ï¼šç¡®è®¤æ˜¯å¦æ¥æ”¶åˆ°éŸ³é¢‘å¯¹è±¡
        st.toast("âœ… æ”¶åˆ°éŸ³é¢‘æ•°æ®ï¼Œæ­£åœ¨ä¸Šä¼ ...", icon="ğŸ“¤")
        
        # æ˜¾ç¤ºéŸ³é¢‘å¤§å°ï¼Œç¡®è®¤ä¸æ˜¯ç©ºæ–‡ä»¶
        # audio_value æ˜¯ä¸€ä¸ª BytesIO å¯¹è±¡
        file_size = audio_value.getbuffer().nbytes
        # st.caption(f"ğŸ”§ è°ƒè¯•ä¿¡æ¯: éŸ³é¢‘å¤§å° {file_size} bytes") 
        
        if file_size > 0:
            with st.spinner("ğŸ‘‚ å°å–µæ­£åœ¨åŠªåŠ›å¬æ¸…æ¥š..."):
                # 2. è°ƒç”¨è¯†åˆ«ï¼ˆç›´æ¥ä¼ é€’ BytesIO å¯¹è±¡ï¼Œä¸éœ€è¦ .read()ï¼‰
                text_result, error = transcribe_audio(audio_value)
            
            if error:
                st.error(f"âŒ è¯†åˆ«æŠ¥é”™: {error}")
            elif not text_result:
                st.warning("âš ï¸ è¯†åˆ«ç»“æœä¸ºç©ºï¼Œå¯èƒ½æ˜¯å£°éŸ³å¤ªå°æˆ–æ²¡è¯´è¯ï¼Ÿ")
            else:
                prompt = text_result
                st.success(f"ğŸ‘‚ å¬åˆ°: {prompt}")
        else:
            st.error("âŒ å½•éŸ³æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™ï¼")
            
    # æ–‡å­—è¾“å…¥å¤‡é€‰
    if not prompt:
        # è¾“å…¥æç¤ºè¯­
        if "input_placeholder" not in st.session_state:
            input_hints = [
                "æˆ–è€…ç›´æ¥æ‰“å­—å–µ~ (å£è¯­æ¨¡å¼)",
                "ä¹Ÿå¯ä»¥æ‰“å­—è¾“å…¥å–µ~ âœ¨",
                "æ‰“å­—ä¹Ÿå¯ä»¥å“¦Nya~ ğŸ’•"
            ]
            st.session_state.input_placeholder = random.choice(input_hints)
        prompt = st.chat_input(st.session_state.input_placeholder)
else:
    # æ™®é€šæ¨¡å¼
    # è¾“å…¥æç¤ºè¯­
    if "input_placeholder" not in st.session_state:
        input_hints = [
            "åœ¨æ­¤å¤„å’Œå°å–µèŠå¤©å–µ~ âœ¨",
            "æƒ³å’Œå°å–µè¯´ä»€ä¹ˆå‘¢ï¼ŸNya~ ğŸ’•",
            "è¾“å…¥ä½ çš„æƒ³æ³•ï¼Œå°å–µåœ¨å¬å“¦~ ğŸ¾",
            "å‘Šè¯‰å°å–µä½ åœ¨æƒ³ä»€ä¹ˆå§~ ğŸŒŸ",
            "å°å–µå‡†å¤‡å¥½å¬ä½ è¯´è¯äº†å–µ~ ğŸ’–"
        ]
        st.session_state.input_placeholder = random.choice(input_hints)
    prompt = st.chat_input(st.session_state.input_placeholder)

# å¤„ç†å¾…å‘é€çš„æ¶ˆæ¯ï¼ˆæ¥è‡ªå¿«æ·å›å¤æˆ–å»ºè®®è¯é¢˜ï¼‰
if "pending_message" in st.session_state:
    prompt = st.session_state.pending_message
    del st.session_state.pending_message

if prompt:
    # 1. å…ˆæŠŠæ¶ˆæ¯å­˜å…¥å†å²
    st.session_state.messages.append({
        "role": "user", 
        "content": prompt,
        "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
    })
    
    # 2. ã€å…³é”®ä¿®å¤ã€‘ç«‹å³åœ¨ç•Œé¢ä¸Šæ¸²æŸ“è¿™æ¡æ¶ˆæ¯
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)
    
    # 3. æ›´æ–°ç»Ÿè®¡
    st.session_state.chat_stats["user_messages"] += 1
    st.session_state.chat_stats["total_chars"] += len(prompt)

    # ========== Agentic Workflow: æ™ºèƒ½ä½“å·¥ä½œæµ ==========
    # åˆå§‹åŒ–æœç´¢å’Œç»˜ç”»ç»“æœ
    search_result = None
    
    # ========== Step 0: æ€è€ƒ - æ„å›¾è¯†åˆ« ==========
    with st.status("ğŸ§  å°å–µæ­£åœ¨æ€è€ƒè¡ŒåŠ¨æ–¹æ¡ˆ...", expanded=False) as status:
        actions = analyze_intent(prompt)
        
        # é€»è¾‘å±è”½ä»£ç æ„å›¾ï¼šå¦‚æœæœªå¼€å¯å­¦éœ¸æ¨¡å¼ï¼Œç§»é™¤ CODE æ„å›¾
        if not st.session_state.get("scholar_pro_mode", False):
            if "CODE" in actions:
                actions.remove("CODE")
            # å¦‚æœç§»é™¤å actions ä¸ºç©ºï¼Œè‡ªåŠ¨æ·»åŠ  CHAT
            if not actions:
                actions.append("CHAT")
        
        status.update(label=f"âœ… è¯†åˆ«åˆ°æ“ä½œï¼š{', '.join(actions)}", state="complete")
        st.write(f"**è¯†åˆ«åˆ°çš„æ“ä½œï¼š** {', '.join(actions)}")
    
    # è·å–å†å²è®°å½•ï¼ˆç”¨äºç»˜å›¾å’Œå¯¹è¯çš„ä¸Šä¸‹æ–‡è®°å¿†ï¼‰
    history_str = get_recent_chat_history()
    
    # ========== æ ¸å¿ƒä¼˜åŒ–ï¼šé€»è¾‘åˆ†æµ ==========
    # è·å–å¼€å…³çŠ¶æ€
    is_scholar_pro = st.session_state.get("scholar_pro_mode", False)
    
    # ğŸš¨ ä¼˜åŒ–ç‚¹ï¼šåªè¦å¼€å¯äº† Pro æ¨¡å¼ï¼Œå¼ºåˆ¶è¿›å…¥ç ”è®¨æµç¨‹ï¼Œå¿½ç•¥æ„å›¾è¯†åˆ«çš„é™åˆ¶
    if is_scholar_pro:
        # --- è¿›å…¥å­¦éœ¸ Pro æ¨¡å¼ (å¼ºåˆ¶) ---
        
        # 1. åˆå§‹åŒ–å˜é‡
        final_solution = None
        success = False
        pro_summary = ""
        
        # 2. Phase 1: æ€è€ƒä¸æ¨å¯¼è¿‡ç¨‹
        # ä½¿ç”¨ status å®¹å™¨ï¼Œç»™ç”¨æˆ·æ˜ç¡®çš„"æ­£åœ¨å¯åŠ¨"åé¦ˆ
        with st.status("ğŸ”¥ å­¦éœ¸ Pro æ¨¡å¼å·²æ¿€æ´»ï¼šæ•™æˆå›¢é˜Ÿæ­£åœ¨å…¥é©»...", expanded=True) as pro_status:
            try:
                # è¿è¡Œæ•™æˆ-åŠ©æ•™å¾ªç¯
                # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥æŠŠ prompt ä¼ è¿›å»ï¼Œä¸å†ä¾èµ– actions é‡Œçš„ CODE
                final_solution, success = run_scholar_pro_mode(prompt, search_result if search_result else "")
                
                if success:
                    pro_status.update(label="âœ… å­¦éœ¸ Pro æ¨¡å¼ç ”è®¨å®Œæˆ", state="complete", expanded=False)
                else:
                    pro_status.update(label="âš ï¸ ç ”è®¨ç»“æŸ (æœªå®Œå…¨é€šè¿‡)", state="complete", expanded=False)
                    
            except Exception as e:
                error_str = str(e)
                if "400" in error_str and "Budget" in error_str:
                    pro_status.update(label="ğŸ’¸ ç»è´¹ä¸è¶³è­¦å‘Š", state="error")
                    st.error("ğŸ˜¿ å“å‘€ï¼å­¦æ ¡å‘çš„ API ç»è´¹ï¼ˆQuotaï¼‰ç”¨å®Œå•¦ï¼DeepSeek-R1 æ•™æˆç½¢å·¥äº†ã€‚\nè¯·å°è¯•å…³é—­ Pro æ¨¡å¼ä½¿ç”¨æ™®é€šæ¨¡å¼ï¼Œæˆ–è€…åˆ‡æ¢ API Key å–µ~")
                else:
                    pro_status.update(label="âŒ å­¦éœ¸ Pro æ¨¡å¼å‡ºé”™", state="error")
                    st.error(f"æ¨å¯¼è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {error_str}")
        
        # 3. Phase 2: æœ€ç»ˆæ±‡æŠ¥
        if final_solution:
            client = get_openai_client()
            
            # æ„å»ºæ±‡æŠ¥ Prompt (ä¿æŒä¸å˜)
            presenter_prompt = f"""ä½ æ˜¯å¯çˆ±çš„å°å–µã€‚è¿™æ˜¯ç»è¿‡æ•™æˆå’ŒåŠ©æ•™å¤šè½®éªŒè¯çš„æœ€ç»ˆå®Œç¾ç­”æ¡ˆï¼š

{final_solution}

è¯·ç”¨ä½ çš„çŒ«å¨˜è¯­æ°”ï¼ˆMeow~, Nya~ï¼‰ï¼ŒæŠŠè¿™ä¸ªç­”æ¡ˆé€šä¿—æ˜“æ‡‚åœ°è®²ç»™ç”¨æˆ·å¬ã€‚ä¿ç•™æ ¸å¿ƒå…¬å¼å’Œç»“è®ºï¼Œä½†è¯­æ°”è¦è½¯èŒã€‚"""
            
            presenter_messages = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": presenter_prompt}
            ]
            
            # æ˜¾ç¤ºæœ€ç»ˆå›å¤
            with st.chat_message("assistant", avatar="ğŸ¾"):
                thinking_box = st.empty()
                thinking_box.caption("ğŸ’­ å°å–µæ­£åœ¨æ•´ç†æœ€ç»ˆç­”æ¡ˆå–µ~ âœ¨")
                res_box = st.empty()
                full_reply = ""
                
                try:
                    completion = client.chat.completions.create(
                        model=MODEL_NAME, # V3
                        messages=presenter_messages,
                        max_tokens=2000,
                        temperature=0.7,
                        stream=True
                    )
                    thinking_box.empty()
                    
                    cursor_states = ["â–ˆ", "â–Š", "â–‹", "â–Œ", "â–", "â–", "â–", " "]
                    cursor_idx = 0
                    for chunk in completion:
                        if chunk.choices[0].delta.content:
                            full_reply += chunk.choices[0].delta.content
                            cursor_idx = (cursor_idx + 1) % len(cursor_states)
                            res_box.markdown(format_deepseek_math(full_reply) + cursor_states[cursor_idx])
                    res_box.markdown(format_deepseek_math(full_reply))
                    
                    # å­˜å…¥å†å²
                    pro_summary = f"ğŸ”¥ **å­¦éœ¸ Pro æ¨¡å¼æ‰§è¡ŒæŠ¥å‘Š**\n\n**æœ€ç»ˆè§£ç­”ï¼š**\n{final_solution}\n\n**å°å–µçš„è§£é‡Šï¼š**\n{full_reply}"
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": pro_summary,
                        "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
                    })
                    st.session_state.chat_stats["assistant_messages"] += 1
                    st.session_state.chat_stats["total_chars"] += len(pro_summary)
                    st.divider()
                    
                except Exception as e:
                    res_box.error(f"ğŸ˜¿ æ±‡æŠ¥å‡ºé”™: {str(e)}")

        # ğŸš¨ å…³é”®ï¼šå¦‚æœæ˜¯ Pro æ¨¡å¼ï¼Œè¿è¡Œå®Œåç›´æ¥ç»“æŸæœ¬æ¬¡å“åº”ï¼Œä¸å†è¿›å…¥ä¸‹é¢çš„ CHAT é€»è¾‘
        # é˜²æ­¢å‡ºç°"æ•™æˆè¯´å®Œè¯ï¼Œå°å–µåˆè‡ªå·±èŠäº†ä¸€é"çš„é‡å¤æƒ…å†µ
        st.stop() 
    
    # ========== Step 1: æœç´¢ (SEARCH) ==========
    if "SEARCH" in actions and SEARCH_AVAILABLE:
        with st.status("ğŸ” å°å–µæ­£åœ¨ç½‘ä¸Šå†²æµªå–µ...", expanded=False) as search_status:
            search_result = perform_web_search(prompt)
            if search_result:
                search_status.update(label="âœ… å·²è·å–è”ç½‘ä¿¡æ¯", state="complete")
                st.write("æœç´¢åˆ°çš„å†…å®¹æ‘˜è¦ï¼š")
                st.caption(search_result[:500] + "..." if len(search_result) > 500 else search_result)
            else:
                search_status.update(label="ğŸ˜¿ æ²¡æ‰¾åˆ°ç›¸å…³ä¿¡æ¯å–µ~", state="error")
    
    # ========== Step 2: ç»˜å›¾ (DRAW) ==========
    if "DRAW" in actions:
        with st.chat_message("assistant", avatar="ğŸ¾"):
            try:
                # å…³é”®é€»è¾‘ï¼šè°ƒç”¨ generate_image_prompt æ—¶ï¼ŒåŠ¡å¿…ä¼ å…¥ search_context å’Œ chat_history
                with st.spinner("ğŸ¨ å°å–µæ­£åœ¨æ„æ€ç”»é¢..."):
                    # ä¼ å…¥ promptã€search_result å’Œ history_strï¼Œè®©ç”Ÿæˆå™¨ç»“åˆä¸Šä¸‹æ–‡è®°å¿†
                    english_prompt = generate_image_prompt(
                        user_prompt=prompt,
                        search_context=search_result if search_result else "",
                        chat_history=history_str
                    )
                
                if not english_prompt:
                    st.error("ğŸ˜¿ ç”Ÿæˆæç¤ºè¯å¤±è´¥ï¼Œå°å–µç”»ä¸å‡ºæ¥å–µ~")
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": "ğŸ˜¿ å¯¹ä¸èµ·ï¼Œå°å–µæ²¡èƒ½ç”Ÿæˆæç¤ºè¯ï¼Œè¯·å†è¯•ä¸€æ¬¡å–µ~",
                        "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
                    })
                    st.session_state.chat_stats["assistant_messages"] += 1
                    
                    # AIè¾“å‡ºç»“æŸåæ·»åŠ åˆ†å‰²çº¿
                    st.divider()
                else:
                    # è°ƒç”¨ FLUX API ç”Ÿæˆå›¾ç‰‡
                    with st.spinner(f"ğŸ–Œï¸ æ­£åœ¨ç»˜åˆ¶ï¼š{english_prompt} ..."):
                        image_data = query_flux_image(english_prompt)
                    
                    if image_data:
                        # æˆåŠŸï¼šæ˜¾ç¤ºå›¾ç‰‡
                        try:
                            # å°†äºŒè¿›åˆ¶æ•°æ®è½¬æ¢ä¸º PIL Image å¹¶æ˜¾ç¤º
                            if PIL_AVAILABLE:
                                image = Image.open(BytesIO(image_data))
                                st.image(image, caption="æˆ‘æ˜¯äº¤å¤§çµé­‚ç”»å¸ˆå–µï¼", width="stretch")
                            else:
                                # å¦‚æœæ²¡æœ‰ PILï¼Œç›´æ¥æ˜¾ç¤ºäºŒè¿›åˆ¶æ•°æ®
                                st.image(image_data, caption="æˆ‘æ˜¯äº¤å¤§çµé­‚ç”»å¸ˆå–µï¼", width="stretch")
                            
                            # ã€æ–°å¢ã€‘å°†å›¾ç‰‡å­˜å…¥ session_state
                            # å°†å›¾ç‰‡è½¬æ¢ä¸º base64 å­—ç¬¦ä¸²ä»¥ä¾¿æŒä¹…åŒ–ä¿å­˜
                            if PIL_AVAILABLE:
                                # å°† PIL Image è½¬æ¢ä¸º base64
                                buffered = BytesIO()
                                image.save(buffered, format="PNG")
                                img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                                image_url = f"data:image/png;base64,{img_base64}"
                            else:
                                # å¦‚æœæ²¡æœ‰ PILï¼Œç›´æ¥ä½¿ç”¨äºŒè¿›åˆ¶æ•°æ®çš„ base64
                                img_base64 = base64.b64encode(image_data).decode('utf-8')
                                image_url = f"data:image/png;base64,{img_base64}"
                            
                            # ä¿å­˜å›¾ç‰‡æ¶ˆæ¯åˆ° session_state
                            st.session_state.messages.append({
                                "role": "assistant",
                                "content": image_url,  # è¿™é‡Œå­˜å›¾ç‰‡çš„ URL æˆ– base64 æ•°æ®
                                "type": "image",       # æ ‡è®°è¿™æ˜¯å›¾ç‰‡
                                "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
                            })
                            
                            # ã€æ–°å¢ã€‘è¿½åŠ ä¸€æ¡åŠ©æ‰‹çš„æ–‡æœ¬å›å¤ï¼Œä½œä¸ºå›¾ç‰‡çš„"é…æ–‡"
                            reply_text = f"ç”»å¥½å•¦å–µ~ âœ¨\n\nè¿™æ˜¯æˆ‘ä¸ºä½ ç”Ÿæˆçš„å›¾ç‰‡ï¼Œä½¿ç”¨çš„é­”æ³•å’’è¯­ï¼ˆPromptï¼‰æ˜¯ï¼š\n> {english_prompt}"
                            if search_result:
                                reply_text += "\n\nâœ… å°å–µå·²ç»æ ¹æ®æœç´¢åˆ°çš„ä¿¡æ¯æ¥è®¾è®¡ç”»é¢äº†å–µ~"
                            st.markdown(reply_text)
                            
                            # è®°å¿†ï¼šå°†æ–‡æœ¬å›å¤å­˜å…¥èŠå¤©å†å²
                            st.session_state.messages.append({
                                "role": "assistant",
                                "content": reply_text,
                                "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
                            })
                            
                            # æ›´æ–°ç»Ÿè®¡
                            st.session_state.chat_stats["assistant_messages"] += 2  # å›¾ç‰‡æ¶ˆæ¯ + æ–‡æœ¬æ¶ˆæ¯
                            st.session_state.chat_stats["total_chars"] += len(reply_text)
                            
                            # AIè¾“å‡ºç»“æŸåæ·»åŠ åˆ†å‰²çº¿
                            st.divider()
                        except Exception as e:
                            st.error(f"ğŸ˜¿ æ˜¾ç¤ºå›¾ç‰‡å¤±è´¥ï¼š{str(e)}")
                            error_reply = "ğŸ˜¿ å¯¹ä¸èµ·ï¼Œå°å–µç”»å¥½äº†ä½†æ˜¯æ˜¾ç¤ºä¸å‡ºæ¥å–µ~ è¯·å†è¯•ä¸€æ¬¡Nya~"
                            st.markdown(error_reply)
                            st.session_state.messages.append({
                                "role": "assistant",
                                "content": error_reply,
                                "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
                            })
                            st.session_state.chat_stats["assistant_messages"] += 1
                            
                            # AIè¾“å‡ºç»“æŸåæ·»åŠ åˆ†å‰²çº¿
                            st.divider()
                    else:
                        # å¤±è´¥ï¼šæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                        error_reply = "ğŸ˜¿ å¯¹ä¸èµ·ï¼Œå°å–µæ²¡èƒ½ç”»å‡ºå›¾ç‰‡å–µ~ å¯èƒ½æ˜¯æ¨¡å‹æ­£åœ¨åŠ è½½ï¼Œè¯·ç¨åå†è¯•Nya~"
                        st.error(error_reply)
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": error_reply,
                            "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
                        })
                        st.session_state.chat_stats["assistant_messages"] += 1
                        
                        # AIè¾“å‡ºç»“æŸåæ·»åŠ åˆ†å‰²çº¿
                        st.divider()
            except Exception as e:
                error_reply = f"ğŸ˜¿ ç»˜ç”»è¿‡ç¨‹ä¸­å‡ºé”™äº†å–µ~: {str(e)}"
                st.error(error_reply)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": error_reply,
                    "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
                })
                st.session_state.chat_stats["assistant_messages"] += 1
                
                # AIè¾“å‡ºç»“æŸåæ·»åŠ åˆ†å‰²çº¿
                st.divider()
    
    # ========== Step 3: å¯¹è¯ (CHAT) ==========
    # åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œå¯¹è¯ï¼š
    # 1. å¦‚æœæ˜ç¡®åŒ…å« CHATï¼Œæ‰§è¡Œå¯¹è¯
    # 2. å¦‚æœæ—¢æ²¡æœ‰ DRAWã€SEARCH ä¹Ÿæ²¡æœ‰ CODEï¼Œæ‰§è¡Œå¯¹è¯ï¼ˆé˜²æ­¢æ— å“åº”ï¼‰
    # 3. å¦‚æœåªæœ‰ SEARCHï¼ˆæ²¡æœ‰ DRAWã€CODE å’Œ CHATï¼‰ï¼Œæ‰§è¡Œå¯¹è¯ï¼ˆæœç´¢ç»“æœéœ€è¦å¯¹è¯ç¯èŠ‚ï¼‰
    # 4. å¦‚æœåªæœ‰ CODEï¼ˆæ²¡æœ‰ CHATï¼‰ï¼Œä¸æ‰§è¡Œå¯¹è¯ï¼ˆCODE å·²ç»ç”Ÿæˆäº†æœ€ç»ˆå›å¤ï¼‰
    should_chat = "CHAT" in actions or ("DRAW" not in actions and "SEARCH" not in actions and "CODE" not in actions) or ("SEARCH" in actions and "DRAW" not in actions and "CODE" not in actions and "CHAT" not in actions)
    
    if should_chat:
        # ç”Ÿæˆå›å¤ï¼ˆå¦‚æœä¹‹å‰æœç´¢è¿‡ï¼Œsearch_result å·²ç»åŒ…å«ç»“æœï¼‰
        # ä¸Šä¸‹æ–‡ï¼šå¦‚æœåˆšæ‰æœ‰äº† search_resultï¼ŒåŠ¡å¿…å°†å…¶æ’å…¥ System Prompt ä¸­ï¼Œè®© AI èƒ½æ ¹æ®æœç´¢ç»“æœå›ç­”é—®é¢˜
        
        with st.chat_message("assistant", avatar="ğŸ¾"):
            # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©æç¤ºæ–‡å­—
            if "use_reasoning_model" in st.session_state and st.session_state.use_reasoning_model:
                thinking_text = "å°å–µæ­£åœ¨ç–¯ç‹‚çƒ§è„‘ä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼ˆå¯èƒ½éœ€è¦å‡ åç§’ï¼‰... ğŸ±ğŸ’¦"
            else:
                thinking_phrases = [
                    "å°å–µæ­£åœ¨æ€è€ƒå–µ~ âœ¨",
                    "è®©æˆ‘æƒ³æƒ³Nya~ ğŸ’«",
                    "å—¯...å–µ~ ğŸŒŸ",
                    "å°å–µåœ¨è®¤çœŸæ€è€ƒå“¦~ ğŸ’•"
                ]
                thinking_text = f"ğŸ’­ {random.choice(thinking_phrases)}"
            
            thinking_box = st.empty()
            thinking_box.caption(thinking_text)
            
            res_box = st.empty()
            full_res = ""
            
            # æ ¹æ®å¼€å…³çŠ¶æ€é€‰æ‹©æ¨¡å‹
            current_model = "deepseek-r1" if ("use_reasoning_model" in st.session_state and st.session_state.use_reasoning_model) else MODEL_NAME
            
            # å°è¯•è°ƒç”¨ï¼Œå¢åŠ å¼‚å¸¸æ•è·
            try:
                # --- æ ¸å¿ƒä¿®æ”¹ï¼šæ„å»ºå¹²å‡€çš„ API æ¶ˆæ¯åˆ—è¡¨ ---
                api_messages = []
                
                # ç¬¬ä¸€æ­¥ï¼šæ ¹æ®æ¨¡å‹ç±»å‹è·å– System Promptï¼ˆåŠ¨æ€æ·»åŠ ï¼‰
                system_prompt = get_system_prompt(current_model)
                if system_prompt:
                    api_messages.append({"role": "system", "content": system_prompt})
                
                # ã€æ–‡æ¡£åŠ©æ‰‹ã€‘å¦‚æœç”¨æˆ·ä¸Šä¼ äº†æ–‡æ¡£ï¼Œæ³¨å…¥æ–‡æ¡£å†…å®¹
                if "current_document_content" in st.session_state and st.session_state.current_document_content:
                    document_content = st.session_state.current_document_content
                    
                    # é˜²æ­¢ Token æ¶ˆè€—è¿‡å¤§ï¼Œé™åˆ¶æ–‡æ¡£é•¿åº¦
                    max_doc_length = 200000
                    if len(document_content) > max_doc_length:
                        document_content = document_content[:max_doc_length] + "\n\n...(æ–‡æ¡£è¿‡é•¿ï¼Œä»…æˆªå–å‰ 20 ä¸‡å­—ç¬¦ï¼Œå»ºè®®åˆ†ç« èŠ‚æŠ•å–‚)..."
                    
                    document_system_msg = {
                        "role": "system",
                        "content": f"ã€ç³»ç»ŸçŸ¥è¯†åº“æ³¨å…¥ã€‘ç”¨æˆ·ä¸Šä¼ äº†ä»¥ä¸‹å‚è€ƒæ–‡æ¡£ï¼Œè¯·åœ¨å›ç­”é—®é¢˜æ—¶ä¼˜å…ˆå‚è€ƒè¿™äº›å†…å®¹ï¼š\n\n{document_content}"
                    }
                    api_messages.append(document_system_msg)
                
                # ã€å…³é”®ã€‘å¦‚æœåˆšæ‰æœ‰äº† search_resultï¼ŒåŠ¡å¿…å°†å…¶æ’å…¥ System Prompt ä¸­
                if search_result:
                    search_system_msg = {
                        "role": "system",
                        "content": f"ã€è¿™æ˜¯å®æ—¶æœç´¢ç»“æœï¼Œè¯·åˆ©ç”¨è¿™äº›ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‘\n\n{search_result}"
                    }
                    api_messages.append(search_system_msg)
                elif "SEARCH" in actions and not search_result:
                    # å¦‚æœæ„å›¾æ˜¯æœç´¢ä½†æœç´¢å¤±è´¥ï¼Œæ·»åŠ è­¦å‘Š
                    search_failed_warning = {
                        "role": "system",
                        "content": "ã€ç³»ç»Ÿè­¦å‘Šã€‘ç½‘ç»œæœç´¢å¤±è´¥ã€‚è¯·ç›´æ¥å‘Šè¯‰ç”¨æˆ·æ— æ³•è¿æ¥ç½‘ç»œï¼Œä¸¥ç¦ç¼–é€ è™šå‡æ–°é—»ã€‚"
                    }
                    api_messages.append(search_failed_warning)
                
                # --- é™åˆ¶å†å²è®°å½•é•¿åº¦ ---
                # åªå–æœ€è¿‘ 20 æ¡æ¶ˆæ¯ï¼Œé˜²æ­¢ Token çˆ†ç‚¸
                recent_messages = st.session_state.messages[-20:]
                
                # --- éå†å†å²è®°å½•ï¼Œè¿›è¡Œä¸¥æ ¼æ¸…æ´— ---
                for msg in recent_messages:
                    # 1. å¤„ç† system è§’è‰²
                    if msg["role"] == "system":
                        # ã€å…³é”®ä¿®å¤ã€‘å¦‚æœæ˜¯è§†è§‰è¯†åˆ«ä¿¡å·ï¼Œå¿…é¡»ä¿ç•™å¹¶åŠ å…¥åˆ—è¡¨ï¼
                        if "[ç³»ç»Ÿè§†è§‰ä¿¡å·]" in str(msg.get("content", "")):
                            api_messages.append({"role": "system", "content": str(msg.get("content", ""))})
                            continue  # å¤„ç†å®Œåç»§ç»­ä¸‹ä¸€æ¬¡å¾ªç¯
                        else:
                            continue  # å…¶ä»–æ™®é€š system æ¶ˆæ¯è·³è¿‡ï¼ˆé¿å…ä¸å¼€å¤´çš„ System Prompt é‡å¤ï¼‰
                    
                    # 2. ã€å…³é”®ã€‘å¦‚æœæ¶ˆæ¯æ ‡è®°ä¸º imageï¼Œç›´æ¥ä¸¢å¼ƒï¼Œç»å¯¹ä¸å‘ç»™ LLM
                    if msg.get("type") == "image":
                        continue
                    
                    # 3. ã€é˜²å¾¡ã€‘è·å–å†…å®¹å¹¶è½¬ä¸ºå­—ç¬¦ä¸²
                    raw_content = str(msg.get("content", ""))
                    
                    # 4. ã€æ ¸å¼¹çº§é˜²å¾¡ã€‘å¦‚æœå•æ¡æ¶ˆæ¯é•¿åº¦è¶…è¿‡ 10,000 å­—ç¬¦ï¼Œåˆ¤å®šä¸ºå¼‚å¸¸æ•°æ®(Base64)ï¼Œå¼ºåˆ¶æˆªæ–­ï¼
                    # æ­£å¸¸çš„èŠå¤©å¯¹è¯ä¸å¯èƒ½å•æ¡è¶…è¿‡ 1 ä¸‡å­—ã€‚
                    if len(raw_content) > 10000:
                        clean_content = raw_content[:1000] + "\n[ç³»ç»Ÿæç¤ºï¼šæ£€æµ‹åˆ°è¶…é•¿å¼‚å¸¸æ•°æ®ï¼Œå·²æˆªæ–­...]"
                    else:
                        clean_content = raw_content
                    
                    api_messages.append({"role": msg["role"], "content": clean_content})
                
                # --- å‘é€æ¸…æ´—åçš„æ•°æ® ---
                client = get_openai_client()
                completion = client.chat.completions.create(
                    model=current_model,
                    messages=api_messages,  # ä½¿ç”¨æ¸…æ´—åçš„åˆ—è¡¨
                    stream=True
                )
                
                # æ¸…é™¤æ€è€ƒæç¤º
                thinking_box.empty()
                
                # æµå¼è¾“å‡ºï¼Œæ·»åŠ å¯çˆ±çš„å…‰æ ‡æ•ˆæœ
                cursor_states = ["â–ˆ", "â–Š", "â–‹", "â–Œ", "â–", "â–", "â–", " "]
                cursor_idx = 0
                
                # å¦‚æœæ˜¯ R1 æ¨¡å¼ï¼Œåœ¨æµå¼è¾“å‡ºæ—¶å°è¯•éšè—æ€è€ƒè¿‡ç¨‹
                is_r1_mode = "use_reasoning_model" in st.session_state and st.session_state.use_reasoning_model
                display_content = ""  # ç”¨äºæ˜¾ç¤ºçš„ä¸´æ—¶å†…å®¹
                final_answer_detected = False  # æ ‡è®°æ˜¯å¦å·²æ£€æµ‹åˆ°æœ€ç»ˆç­”æ¡ˆ
                last_thinking_state = False  # è®°å½•ä¸Šä¸€æ¬¡æ˜¯å¦åœ¨æ€è€ƒä¸­ï¼Œç”¨äºå‡å°‘é‡å¤æ¸²æŸ“
                
                for chunk in completion:
                    if chunk.choices[0].delta.content:
                        full_res += chunk.choices[0].delta.content
                        
                        # å¦‚æœæ˜¯ R1 æ¨¡å¼ï¼Œå®æ—¶æ£€æµ‹æ€è€ƒçŠ¶æ€
                        if is_r1_mode:
                            # æ£€æµ‹æ˜¯å¦è¿˜åœ¨ç”Ÿæˆæ€è€ƒå†…å®¹
                            # R1 ä½¿ç”¨ <think> æ ‡ç­¾
                            has_open_tag = "<think>" in full_res
                            has_close_tag = "</think>" in full_res
                            
                            # æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ€è€ƒä¸­ï¼ˆæœ‰å¼€å§‹æ ‡ç­¾ä½†æ²¡æœ‰ç»“æŸæ ‡ç­¾ï¼‰
                            is_thinking = has_open_tag and not has_close_tag
                            
                            if is_thinking:
                                # æ­£åœ¨æ€è€ƒä¸­ï¼Œæ˜¾ç¤ºå ä½ç¬¦ï¼ˆåªåœ¨çŠ¶æ€æ”¹å˜æ—¶æ›´æ–°ï¼Œå‡å°‘é‡å¤æ¸²æŸ“ï¼‰
                                if not last_thinking_state:
                                    res_box.markdown("ğŸ§  å°å–µæ­£åœ¨æ·±åº¦æ€è€ƒä¸­... (è¯·ç¨å€™)")
                                    last_thinking_state = True
                            else:
                                # æ€è€ƒå·²ç»“æŸæˆ–æœªå¼€å§‹ï¼Œå°è¯•è§£ææœ€ç»ˆç­”æ¡ˆ
                                thinking_content, final_answer = parse_r1_response(full_res)
                                
                                if final_answer and final_answer.strip():
                                    # å·²è§£æå‡ºæœ€ç»ˆç­”æ¡ˆï¼Œå¼€å§‹æµå¼æ¸²æŸ“
                                    if not final_answer_detected:
                                        final_answer_detected = True
                                        last_thinking_state = False
                                    
                                    display_content = final_answer
                                    cursor_idx = (cursor_idx + 1) % len(cursor_states)
                                    formatted_content = format_deepseek_math(display_content)
                                    res_box.markdown(formatted_content + cursor_states[cursor_idx])
                                else:
                                    # æ€è€ƒå·²ç»“æŸï¼Œä½†æœ€ç»ˆç­”æ¡ˆè¿˜æœªå¼€å§‹ï¼Œç»§ç»­æ˜¾ç¤ºå ä½ç¬¦
                                    if last_thinking_state or not final_answer_detected:
                                        res_box.markdown("ğŸ§  å°å–µæ­£åœ¨æ·±åº¦æ€è€ƒä¸­... (è¯·ç¨å€™)")
                                        last_thinking_state = True
                        else:
                            # V3 æ¨¡å¼ï¼Œæ­£å¸¸æ˜¾ç¤º
                            display_content = full_res
                            cursor_idx = (cursor_idx + 1) % len(cursor_states)
                            formatted_content = format_deepseek_math(display_content)
                            res_box.markdown(formatted_content + cursor_states[cursor_idx])
                
                # æœ€ç»ˆæ˜¾ç¤ºï¼Œå¤„ç† R1 çš„æ€è€ƒè¿‡ç¨‹
                if is_r1_mode:
                    # é‡æ–°è§£ææ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆï¼ˆç¡®ä¿å®Œæ•´ï¼‰
                    thinking_content, final_answer = parse_r1_response(full_res)
                    
                    if thinking_content:
                        # å¦‚æœæœ‰æ€è€ƒè¿‡ç¨‹ï¼Œç”¨å¯æŠ˜å çš„æ–¹å¼æ˜¾ç¤º
                        with st.expander("ğŸ§  æŸ¥çœ‹å°å–µçš„æ€è€ƒè¿‡ç¨‹", expanded=False):
                            st.markdown(f"```\n{thinking_content}\n```")
                        # åªæ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆï¼Œæ ¼å¼åŒ–æ•°å­¦å…¬å¼
                        final_display = final_answer if final_answer else full_res
                        res_box.markdown(format_deepseek_math(final_display))
                    else:
                        # æ²¡æœ‰æ€è€ƒè¿‡ç¨‹ï¼Œæ­£å¸¸æ˜¾ç¤ºï¼Œæ ¼å¼åŒ–æ•°å­¦å…¬å¼
                        res_box.markdown(format_deepseek_math(full_res))
                else:
                    # V3 æ¨¡å¼ï¼Œæ­£å¸¸æ˜¾ç¤ºï¼Œæ ¼å¼åŒ–æ•°å­¦å…¬å¼
                    res_box.markdown(format_deepseek_math(full_res))
                
                # ä¿å­˜å®Œæ•´å›å¤åˆ°æ¶ˆæ¯å†å²
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_res,
                    "timestamp": (datetime.now() + timedelta(hours=8)).isoformat()
                })
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                st.session_state.chat_stats["assistant_messages"] += 1
                st.session_state.chat_stats["total_chars"] += len(full_res)
                
                # éšæœºæ˜¾ç¤ºå¯çˆ±çš„å®Œæˆååº”
                reactions = [
                    "âœ¨ å°å–µè¯´å®Œäº†å–µ~",
                    "ğŸ’• å¸Œæœ›å°å–µçš„å›ç­”æœ‰å¸®åŠ©Nya~",
                    "ğŸ¾ å°å–µå¾ˆå¼€å¿ƒèƒ½å¸®åˆ°ä½ ~",
                    "ğŸŒŸ è¿˜æœ‰ä»€ä¹ˆæƒ³é—®å°å–µçš„å—ï¼Ÿ"
                ]
                if random.random() < 0.3:  # 30%æ¦‚ç‡æ˜¾ç¤º
                    st.caption(f"ğŸ’« {random.choice(reactions)}")
                
                # === æ–°å¢ï¼šå£è¯­æ¨¡å¼è‡ªåŠ¨æ’­æ”¾è¯­éŸ³ ===
                if st.session_state.get("practice_mode", False):
                    # åªæœ‰å½“å›å¤ä¸å¤ªé•¿æ—¶æ‰æœ—è¯»ï¼Œé¿å…ç­‰å¾…è¿‡ä¹…
                    if len(full_res) < 500:
                        play_ai_voice(full_res)
                
                # AIè¾“å‡ºç»“æŸåæ·»åŠ åˆ†å‰²çº¿
                st.divider()
                    
            except Exception as e:
                thinking_box.empty()
                error_messages = [
                    f"ğŸ˜¿ å“å‘€ï¼Œå°å–µé‡åˆ°äº†ä¸€ç‚¹é—®é¢˜å–µ~: {str(e)}",
                    f"ğŸ’” å°å–µå‡ºé”™äº†ï¼Œå¯¹ä¸èµ·Nya~: {str(e)}",
                    f"ğŸ˜¢ å°å–µéœ€è¦å¸®åŠ©äº†å–µ~: {str(e)}"
                ]
                st.error(random.choice(error_messages))
                
                # AIè¾“å‡ºç»“æŸåæ·»åŠ åˆ†å‰²çº¿
                st.divider()

# --- åº•éƒ¨ä¿¡æ¯ ---
st.markdown("<div style='height: 2rem;'></div>", unsafe_allow_html=True)

st.caption("<div style='text-align: center; opacity: 0.6;'>ğŸ’– Powered by SJTU Model Service | v2025.12.25</div>", unsafe_allow_html=True)